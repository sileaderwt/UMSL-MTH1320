[["index.html", "16.3.60 Introduction", " 16.3.60 2021-05-26 Introduction This document is an open source project which is designed as supplemental material on homework problems in MTH 1320 (not for teaching purpose) DISCLAIMER: SI leader does not teach the class. I am personally not at that academic level. It is a great opportunity to have chance to work with you, professor Covert, and professor Sager in this semester. If you have any academic question related to content in this class, you should ask professor Covert and professor Sager. This document shows how to use R to get data in each chapter which is introduced in video lectures. There are more than one way to solve problems. These could not be the best approaches. If you come up with something more efficient, please feel free to share!! Short story I have been working as a SI leader for a half of a year. I realize there are two main phases to study statistic. As you can see from the picture, these two phases are overlaped with each other. Since MTH 1320 is the first statistic class level which is required for many majors including non-STEM majors, there are many challenges for non-STEM students working on phase 2. I have seen a friend studying Nursing spends hours each week just only to get the right data for a question which I personally think it is an ineffiecient way to study and we should spend more time in phase 1. Statistic is much more than just getting the right number. This document helps us to reduce the time we spend on phase 2. Open source project SI leader - University of Missouri St. Louis The MIT License (MIT) Copyright © &lt;2021&gt; &lt;Warren&gt; "],["notice.html", "Notice", " Notice There are two main reasons that this document does not use third party package. We do not know which formulas they use behind the scene and sometimes it is hard to retrieve data. We could avoid technical difficulties. We do not have to keep up to date every time that third party changes their package. The document uses formulas from the book and these formulas have a long history with statistic which means they are consistent over time. We could write our third party package based on these formulas. The way that R round number is slightly differen than the book. round(1.5, 0) ## [1] 2 round(.15,1) ## [1] 0.1 To have a better understanding about how round() works, we could read the instruction from help() help(round) "],["install-r.html", "Install R", " Install R Install R https://www.r-project.org/ Choose the right version for your device. Run R Console Install R studio We select RStudio Desktop Free version https://www.rstudio.com/products/rstudio/download/#download We can follow the instruction from the link. First, we need to install R in our computers. Second, we download and install R studio for desktop. Online compiler https://rdrr.io/snippets/ We can install package in this online compiler so it is possible to do mid-term and final project. Hope that helps! "],["import-data-from-excel-to-r.html", "Import data from Excel to R", " Import data from Excel to R First, we need to select import dataset from Excel Select Browse Select the right Excel file Change the name to make it easy to use data &lt;- read.csv(&quot;https://raw.githubusercontent.com/sileaderwt/MTH1320-UMSL/main/Image%2BData/Import%20data/Data1.csv&quot;) data ## A ## 1 C ## 2 B ## 3 E ## 4 B ## 5 A ## 6 B ## 7 C ## 8 A ## 9 B ## 10 C ## 11 C ## 12 B ## 13 E ## 14 C ## 15 D ## 16 B ## 17 C ## 18 A ## 19 C ## 20 A ## 21 C ## 22 B ## 23 E ## 24 A The first row is converted to the name of the data. If the data from Excel does not have a name, we will miss one value by importing directly from Excel. To avoid that, we should move the data from the first row to the last and give a name for the data. For example, in the second data sheet I move A to the last row and give x as the name of the data. data2 &lt;- read.csv(&quot;https://raw.githubusercontent.com/sileaderwt/MTH1320-UMSL/main/Image%2BData/Import%20data/Data2.csv&quot;) data2 ## x ## 1 C ## 2 B ## 3 E ## 4 B ## 5 A ## 6 B ## 7 C ## 8 A ## 9 B ## 10 C ## 11 C ## 12 B ## 13 E ## 14 C ## 15 D ## 16 B ## 17 C ## 18 A ## 19 C ## 20 A ## 21 C ## 22 B ## 23 E ## 24 A ## 25 A We can retrieve the data by using its name y = data2$x y ## [1] &quot;C&quot; &quot;B&quot; &quot;E&quot; &quot;B&quot; &quot;A&quot; &quot;B&quot; &quot;C&quot; &quot;A&quot; &quot;B&quot; &quot;C&quot; &quot;C&quot; &quot;B&quot; &quot;E&quot; &quot;C&quot; &quot;D&quot; &quot;B&quot; &quot;C&quot; &quot;A&quot; &quot;C&quot; ## [20] &quot;A&quot; &quot;C&quot; &quot;B&quot; &quot;E&quot; &quot;A&quot; &quot;A&quot; "],["frequency-distribution.html", "2.2.25 frequency distribution", " 2.2.25 frequency distribution A list of college wrestling champions for the years 1981dash 2005 is given in the table. Each college has been associated with a particular letter. Use this data to complete parts (a) through (d). (a) Determine a frequency distribution. First, we need to import the data from Excel. (For simplicity, this imports mannual by hand, we can get the same result by importing dataset from Excel) data &lt;- c(&quot;C&quot;, &quot;B&quot;, &quot;E&quot;, &quot;B&quot;, &quot;A&quot;, &quot;B&quot;, &quot;C&quot;, &quot;A&quot;, &quot;B&quot;, &quot;C&quot;, &quot;C&quot;, &quot;B&quot;, &quot;E&quot;, &quot;C&quot;, &quot;D&quot;, &quot;B&quot;, &quot;C&quot;, &quot;A&quot;, &quot;C&quot;, &quot;A&quot;, &quot;C&quot;, &quot;B&quot;, &quot;E&quot;, &quot;A&quot;, &quot;A&quot;) data ## [1] &quot;C&quot; &quot;B&quot; &quot;E&quot; &quot;B&quot; &quot;A&quot; &quot;B&quot; &quot;C&quot; &quot;A&quot; &quot;B&quot; &quot;C&quot; &quot;C&quot; &quot;B&quot; &quot;E&quot; &quot;C&quot; &quot;D&quot; &quot;B&quot; &quot;C&quot; &quot;A&quot; &quot;C&quot; ## [20] &quot;A&quot; &quot;C&quot; &quot;B&quot; &quot;E&quot; &quot;A&quot; &quot;A&quot; We can get the frequency by using table() command table(data) ## data ## A B C D E ## 6 7 8 1 3 To display frenquency table in column format use cbind() command cbind(table(data)) ## [,1] ## A 6 ## B 7 ## C 8 ## D 1 ## E 3 (b) Obtain a relative-frequency distribution. To display relative frenquency table in column format use cbind() command cbind(table(data)/length(data)) ## [,1] ## A 0.24 ## B 0.28 ## C 0.32 ## D 0.04 ## E 0.12 To display the result appropriate to 5 decimal places use print() command In this case, we have nice results so it does not show the difference. print(table(data)/length(data), 5) ## data ## A B C D E ## 0.24 0.28 0.32 0.04 0.12 (c) Draw a pie chart. Choose the correct chart below. Store relative-frequency table in a variable x x &lt;- table(data)/length(data) Display pie chart using pie() command pie(x) pie(x, labels = x) (d) Construct a bar chart. Choose the correct chart below. Display bar chart using barplot() command barplot(x) Hope that helps! "],["relative-frequency-distribution.html", "2.3.65 relative-frequency distribution", " 2.3.65 relative-frequency distribution A simple quantitative data set has been provided. Use limit grouping with a first class of 0-4and a class width of 5 to complete parts (a) through (d) for this data set. (a) Determine a frequency distribution. First, we need to import the data from Excel. (For simplicity, this imports mannual by hand, we can get the same result by importing dataset from Excel) data &lt;- c(21, 6, 2, 4, 2, 23, 17, 9, 24, 12, 3, 22, 26, 28, 9, 18, 4, 27, 0, 26) data ## [1] 21 6 2 4 2 23 17 9 24 12 3 22 26 28 9 18 4 27 0 26 We can get the frequency by using table() command table(data) ## data ## 0 2 3 4 6 9 12 17 18 21 22 23 24 26 27 28 ## 1 2 1 2 1 2 1 1 1 1 1 1 1 2 1 1 To display bin frenquency table use as.data.frame() command k = as.data.frame(table(cut(data, breaks=seq(0,30, by=5)))) k ## Var1 Freq ## 1 (0,5] 5 ## 2 (5,10] 3 ## 3 (10,15] 1 ## 4 (15,20] 2 ## 5 (20,25] 4 ## 6 (25,30] 4 Since R does not count the value 0, we could double check the value in range 0-4 and readjust the value f = k$Freq f ## [1] 5 3 1 2 4 4 f[1] = 6 f ## [1] 6 3 1 2 4 4 (b) Obtain a relative-frequency distribution. To display relative frenquency table in column format use cbind() command f/length(data) ## [1] 0.30 0.15 0.05 0.10 0.20 0.20 To display the result appropriate to 5 decimal places use print() command In this case, we have nice results so it does not show the difference. print(f/length(data), digits = 5) ## [1] 0.30 0.15 0.05 0.10 0.20 0.20 (c) Construct a frequency histogram based on your result from part (a). Choose the correct histogram below. Display bar chart using barplot() command barplot(f) (d) Construct a relative-frequency histogram based on your result from part (b). Choose the correct histogram below. The relative-frequency histogram should have the same behavior with the one in part (c). We can get histogram plot by using barplot() command barplot(f/length(data)) Hope that helps! "],["steam-leaf.html", "2.3.77 steam-leaf", " 2.3.77 steam-leaf A quantitative data set is provided in the table. Construct a stem-and-leaf diagram for the data, using one line per stem. Choose the correct stem-and-leaf diagram. First, we need to import the data from Excel. (For simplicity, this imports mannual by hand, we can get the same result by importing dataset from Excel) data &lt;- c(40, 59, 45, 41, 62, 25, 43, 57, 35, 31) data ## [1] 40 59 45 41 62 25 43 57 35 31 We can get stem-and-leaf diagram by using stem() command. stem(data) ## ## The decimal point is 1 digit(s) to the right of the | ## ## 2 | 5 ## 3 | 15 ## 4 | 0135 ## 5 | 79 ## 6 | 2 It is important to know how to get stem-and-leaf diagram. In this case, we rewrite each data value by split them into smaller digits. data ## [1] 40 59 45 41 62 25 43 57 35 31 40 -&gt; 4|0 59 -&gt; 5|9 45 -&gt; 4|5 41 -&gt; 4|1 62 -&gt; 6|2 43 -&gt; 4|3 … Add them together and arrange the number in increasing order, we have the final stem-and-leaf diagram and 2|5 3|1 5 4|0 1 3 5 … Hope that helps! "],["mean-mode-and-median.html", "3.1.19 mean, mode, and median", " 3.1.19 mean, mode, and median A concrete mix is designed to withstand 3000 pounds per square inch (psi) of pressure. The following data represent the strength of nine randomly selected casts (in psi). Compute the mean, median and mode strength of the concrete (in psi). Recommended find manually in Excel even number of data set - type 5 odd number of data set - type 1 First, we need to import the data from Excel. (For simplicity, this imports manually by hand, we can get the same result by importing dataset from Excel) x &lt;- c(3970, 4080, 3100, 3200, 2930, 3830, 4080, 4040, 3530) x ## [1] 3970 4080 3100 3200 2930 3830 4080 4040 3530 We can sort the data sort(x) ## [1] 2930 3100 3200 3530 3830 3970 4040 4080 4080 Compute the mean strength of the concrete. mean(x) ## [1] 3640 Compute the median strength of the concrete. median(x) ## [1] 3830 length(x) ## [1] 9 Since we have odd amount of data summary(x, quantile.type = 1) ## Min. 1st Qu. Median Mean 3rd Qu. Max. ## 2930 3200 3830 3640 4040 4080 Compute the mode strength of the concrete. table(x) ## x ## 2930 3100 3200 3530 3830 3970 4040 4080 ## 1 1 1 1 1 1 1 2 Hope that helps! "],["quartiles.html", "3.4.171 quartiles", " 3.4.171 quartiles An article by a researcher reported on a long-term study of the effects of hurricanes on tropical streams in forests. The study shows that one particular hurricane had a significant impact on stream water chemistry. The following table shows a sample of 10 ammonia fluxes in the first year after the hurricane. Data are in kilograms per hectare per year. Complete parts (a) through (e) below. Recommanded find quatiles mannually in Excel since there is inconsistent approach in R even number of data set - type 5 odd number of data set - type 1 First, we need to import the data from Excel. (For simplicity, this imports mannual by hand, we can get the same result by importing dataset from Excel) x &lt;- c(88, 171, 64, 159, 89, 84, 180, 126, 123, 91) x ## [1] 88 171 64 159 89 84 180 126 123 91 (a). Obtain and interpret the quartiles Since we have even number of summary(x, quantile.type=5) ## Min. 1st Qu. Median Mean 3rd Qu. Max. ## 64.0 88.0 107.0 117.5 159.0 180.0 quantile(x, type=5) ## 0% 25% 50% 75% 100% ## 64 88 107 159 180 (b).Determine and interpret the interquartile range (IQR). We use the formula $IQR = Q_3-Q_1 $ 159-88 ## [1] 71 (c). Find and interpret the five-number summary. We can see the summary from part (a) To interpret five-number summary, we plot boxplot of data boxplot(quantile(x, type=5)) (d). Identify potential outliers, if any. Choose the correct answer below and, if necessary, fill in the answer box to complete your choice Lower limit = \\(Q_1 - 1.5.IQR\\) Upper limit = \\(Q_3 + 1.5.IQR\\) Lower limit 88 - 1.5 * 71 ## [1] -18.5 Upper limit 159 + 1.5 * 71 ## [1] 265.5 Sort our data sort(x) ## [1] 64 84 88 89 91 123 126 159 171 180 Hope that helps! "],["population-mean.html", "3.5.199 population mean", " 3.5.199 population mean The heights, in inches, of the starting five players on a college basketball team are given below. Regarding the five players as a population, solve the following problems. First, we need to import the data from Excel. (For simplicity, this imports mannual by hand, we can get the same result by importing dataset from Excel) x &lt;- c(69, 72, 77 ,75, 85) x ## [1] 69 72 77 75 85 (a). Compute the population mean height, \\(\\mu\\) mean(x) ## [1] 75.6 (b). Compute the population standard deviation of the heights, \\(\\sigma\\) sd(x)*sqrt((length(x)-1)/length(x)) ## [1] 5.425864 Round to one decimal place round(sd(x)*sqrt((length(x)-1)/length(x)), 1) ## [1] 5.4 Hope that helps! "],["deck-card.html", "4.1.14 deck card", " 4.1.14 deck card An ordinary deck of playing cards has 52 cards. There are four suitslong dash spades, hearts, diamonds, and clubslong dash with 13 cards in each suit. Spades and clubs are black; hearts and diamonds are red. If one of these cards is selected at random, what is the probability that it is (a). The probability of selecting a jack is From the image, there are 4 jack cards. So the probability is \\(\\frac{4}{52}=\\frac{1}{13}\\) (b). The probability of selecting a red card is From the image, there are 26 jack cards. So the probability is \\(\\frac{26}{52}=\\frac{1}{2}\\) (c). The probability of selecting a card that is not a heart is There are 13 heart cards. So the probability is \\(\\frac{52-13}{52}=\\frac{3}{4}\\) Hope that helps! "],["probability-distribution.html", "5.2.31 probability distribution", " 5.2.31 probability distribution The random variable X is the crew size of a randomly selected shuttle mission. Its probability distribution is shown below. Complete parts a through c. data &lt;- read.csv(&quot;https://raw.githubusercontent.com/sileaderwt/MTH1320-UMSL/main/Image%2BData/5.2.31%20%20probability%20distribution/5.2.31.csv&quot;) data ## x P.X.x. ## 1 2 0.034 ## 2 3 0.013 ## 3 4 0.072 ## 4 5 0.338 ## 5 6 0.210 ## 6 7 0.289 ## 7 8 0.044 We store data into two variables x and P x = data$x x ## [1] 2 3 4 5 6 7 8 P = data$P.X.x. P ## [1] 0.034 0.013 0.072 0.338 0.210 0.289 0.044 (a). Find and interpret the mean of the random variable. mu = sum(x*P) mu ## [1] 5.72 Round to three decimal places round(mu, 3) ## [1] 5.72 (b). Obtain the standard deviation of the random variable. We can find standard deviation by using formula \\(\\sigma=\\sqrt{\\sum(x-\\mu)^2P(X=x)}\\) sigma = sqrt(sum((x-mu)^2*P)) sigma ## [1] 1.293677 Round to three decimal places round(sigma, 3) ## [1] 1.294 We can use alternative formula to find standarad deviation \\(\\sigma=\\sqrt{\\sum x^2P(X=x)- \\mu^2}\\) sigma2 = sqrt(sum(x^2*P)-mu^2) sigma2 ## [1] 1.293677 (c). Draw a probability histogram for the random variable. Choose the correct graph below. barplot(P, names.arg = x) Hope that helps! "],["area-from-z-score.html", "6.2.61 area from z-score", " 6.2.61 area from z-score Determine the area under the standard normal curve that lies to the right of left parenthesis a right (a) z = -0.74 (b) z= -0.24 (c) z= -0.39 and (d) z= -0.12 (a) The area to the right of z= -0.74 is Using pnorm() return the area to the left, in order to get the area to the right use 1 - pnorm() 1-pnorm(-0.74) ## [1] 0.77035 Round to four decimal places as needed. Use round() command round(1-pnorm(-0.74), 4) ## [1] 0.7704 (b) The area to the right of z= -0.24 is (c) The area to the right of z= -0.39 is (d) The area to the right of z= -0.12 is Using the same approachh to get the answer round(1-pnorm(-0.24), 4) ## [1] 0.5948 round(1-pnorm(-0.39), 4) ## [1] 0.6517 round(1-pnorm(-0.12), 4) ## [1] 0.5478 Hope that helps! "],["z-score.html", "6.2.75 z-score", " 6.2.75 z-score Use a standard normal distribution table to obtain the z-score that has an area of 0.99 to its right. Put the area to the left into qnorm(), it returns z-score Since we have the area to the right qnorm(1-.99) ## [1] -2.326348 Round to two decimal places using round() command round(qnorm(1-.99),2) ## [1] -2.33 Hope that helps! "],["z-score-percentage.html", "6.3.97 z-score, percentage", " 6.3.97 z-score, percentage According to a recent study, the carapace length for adult males of a certain species of tarantula are normally distributed with a mean of \\(\\mu\\) = 17.14 mm and a standard deviation of \\(\\sigma\\) = 1.88 mm. Complete parts (a) through (d) below. (a)Find the percentage of the tarantulas that have a carapace length between 15 mm and 16 mm. First, we need to find z-score for 15mm and 16mm by using the formula \\(z=\\frac{x-\\mu}{\\sigma}\\) (15-17.14)/1.88 ## [1] -1.138298 (16-17.14)/1.88 ## [1] -0.606383 We get each probability to the left by using pnorm() command or using the table pnorm((16-17.14)/1.88 ) ## [1] 0.2721302 pnorm((15-17.14)/1.88 ) ## [1] 0.1274981 In order to get the data between the range 15 and 16 we subtract these probabilities above pnorm((16-17.14)/1.88)-pnorm((15-17.14)/1.88) ## [1] 0.1446322 Round the answer two four decimal places round(pnorm((16-17.14)/1.88)-pnorm((15-17.14)/1.88), 4) ## [1] 0.1446 (b) Find the percentage of the tarantulas that have a carapace length exceeding 18 mm. First, we need to find z-score for 18mm (18-17.14)/1.88 ## [1] 0.4574468 We get each probability to the left by using pnorm() command or using the table pnorm((18-17.14)/1.88 ) ## [1] 0.676325 In order to get the data exceeding 18 mm 1-pnorm((18-17.14)/1.88) ## [1] 0.323675 Round the answer two four decimal places round(1-pnorm((18-17.14)/1.88), 4) ## [1] 0.3237 (c) Determine and interpret the quartiles for the carapace length of these tarantulas. The area to the left of the first quartile is .25 Using qnorm() to get the z-value qnorm(.25) ## [1] -0.6744898 Using the formula \\(x = \\mu + \\sigma . z\\) 17.14 + 1.88 * qnorm(.25) ## [1] 15.87196 round(17.14 + 1.88 * qnorm(.25), 2) ## [1] 15.87 Since the area to the left of second and third quartile are .5 and .75 Using the same approach we have round(17.14 + 1.88 * qnorm(.5), 2) ## [1] 17.14 round(17.14 + 1.88 * qnorm(.75), 2) ## [1] 18.41 (d) Obtain the 95th percentile for the carapace length of these tarantulas The area to the left of 95th percentile is .95 round(17.14 + 1.88 * qnorm(.95), 2) ## [1] 20.23 Hope that helps! "],["population-and-sample-means.html", "7.1.13 population and sample means", " 7.1.13 population and sample means The data in the table represent the ages of the winners of an award for the past five years. Use the data to answer questions (a) through (e). (Assume that sampling is without replacement.) (a)Find the population mean age of the five winners. First, we need to import the data from Excel. Illustrations shows importing data mannually data &lt;- c(37,42,49,49,43) We use mean() command to find the population mean mean(data) ## [1] 44 (b) For samples of size 3, construct a table of all possible samples and their sample means. To construct the table of all possible samples of size 3, we use combn() command combn(data,3) ## [,1] [,2] [,3] [,4] [,5] [,6] [,7] [,8] [,9] [,10] ## [1,] 37 37 37 37 37 37 42 42 42 49 ## [2,] 42 42 42 49 49 49 49 49 49 49 ## [3,] 49 49 43 49 43 43 49 43 43 43 To find sample mean, we run x = combn(data, 3, mean) x ## [1] 42.66667 42.66667 40.66667 45.00000 43.00000 43.00000 46.66667 44.66667 ## [9] 44.66667 47.00000 Round the answer to 2 decimal places print(x, 4) ## [1] 42.67 42.67 40.67 45.00 43.00 43.00 46.67 44.67 44.67 47.00 (c) Draw a dotplot for the sampling distribution of the sample mean for samples of size 3. Choose the correct dotplot below. To draw a dotplot for sample mean, we use stripchart() command. method=“stack” shows the data on top of each other. pch=20 represents dark circle as a data. cex=3 indicates the size of circle. stripchart(x, method=&quot;stack&quot;, pch=20, cex =3) R provides dotchart() command which gives a chart slightly different from the one in Pearson. You could try it by running dotchart() dotchart(as.numeric(x)) (d) For a random sample of size 3, what is the chance that the sample mean will equal the population mean? Firstly, we need to round sample means to 2 decimal places x = round(x,2) x ## [1] 42.67 42.67 40.67 45.00 43.00 43.00 46.67 44.67 44.67 47.00 We can use table() command to get the frequency table table(x) ## x ## 40.67 42.67 43 44.67 45 46.67 47 ## 1 2 2 2 1 1 1 We can check mannually z.if the mean is in the frequency table or we can run table(x)[names(table(x)) == 44] ## named integer(0) Since the frequency is 0, the chance is 0 (e) For a random sample of size 3, obtain the probability that the sampling error made in estimating the population mean by the sample mean will be 3 years or less; that is, determine the probability that x overbar will be within 3 years of mu. To find the lower and upper bound, we run 44 - 3 ## [1] 41 44 + 3 ## [1] 47 We can use table() command to get the frequency table table(x) ## x ## 40.67 42.67 43 44.67 45 46.67 47 ## 1 2 2 2 1 1 1 Since the frequency between these range is 9, we can find the probability by running 9/length(x) ## [1] 0.9 Hope that helps! "],["sample-standard-deviation.html", "7.3.73 sample standard deviation", " 7.3.73 sample standard deviation An ethanol railroad tariff is a fee charged for shipments of ethanol on public railroads. An agricultural association publishes tariff rates for railroad-car shipments of ethanol. Assuming that the standard deviation of such tariff rates is $ 1300 ,determine the probability that the mean tariff rate of 350 randomly selected railroad-car shipments of ethanol will be within $110 of the mean tariff rate of all railroad-car shipments of ethanol. Interpret your answer in terms of sampling error. The probability is (Round to three decimal places as needed) The sample size n = 350 since there are 350 tariff randomly selected. Since the sample size is more than 30, the variable is normally distributed followed by the central limit theorem. Population standard deviation \\(\\sigma=1300\\) n = 350 sigma = 1300 First we need to find sample standard deviation by using the formula \\(\\sigma_{\\bar{x}}=\\frac{\\sigma}{\\sqrt{n}}\\) s = sigma/sqrt(n) s ## [1] 69.48792 Next, we need to find the test statistic by using the formula \\(z=\\frac{x-\\mu}{\\sigma}\\) Since our estimated points are within 110 of the mean, so $x = $ . It follows that \\(z=\\frac{\\pm110}{\\sigma_{\\bar{x}}}\\) 110 / s ## [1] 1.583009 -110/ s ## [1] -1.583009 We can get the area between two estimated points by using pnorm() pnorm(110 / s) - pnorm(-110 / s) ## [1] 0.8865806 Round to three decimal places round(pnorm(110 / s) - pnorm(-110 / s) , 3) ## [1] 0.887 Hope that helps! "],["population-mean-confidence-interval.html", "8.1.11 population mean, confidence interval", " 8.1.11 population mean, confidence interval For the provided sample mean, sample size, and population standard deviation, complete parts (a) through (c) below \\(\\bar{x}=37, n=64, \\sigma=3\\) (a). Find a 95% confidence interval for the population mean. First, we need to get the data from the question x = 37 n = 64 sigma = 3 Empirical rule: 99.7% - 1 standard deviation 95% - 2 standard deviation 68% - 3 standard deviation To find 95% confidence interval, we run x - 2 * sigma/sqrt(n) ## [1] 36.25 x + 2 * sigma/sqrt(n) ## [1] 37.75 Round to two decimal places as needed round(x - 2 * sigma/sqrt(n), 2) ## [1] 36.25 round(x + 2 * sigma/sqrt(n), 2) ## [1] 37.75 (b). Identify and interpret the margin of error. Margin of error = 1/2 distance of two endpoints of confidence interval (round(x + 2 * sigma/sqrt(n), 2) - round(x - 2 * sigma/sqrt(n), 2)) /2 ## [1] 0.75 (c). Express the endpoints of the confidence interval in terms of the point estimate and the margin of error. We can find margin of error round( 2 * sigma/sqrt(n), 2) ## [1] 0.75 Hope that helps! "],["point-estimated.html", "8.1.7 point estimated", " 8.1.7 point estimated A simple random sample is taken from a population and yields the following data for a variable of the population. Find a point estimate for the population mean (that is, the mean of the variable). First, we need to get the data from Excel. (The approach below gets the data mannually) data &lt;- c(11, 23, 38, 13, 35, 16, 36, 19, 16, 27) To find point estimated, we run mean(data) ## [1] 23.4 Round to one decimal place as needed round(mean(data), 1) ## [1] 23.4 Hope that helps! "],["one-mean-z-interval-procedure.html", "8.2.63 one-mean-z-interval procedure", " 8.2.63 one-mean-z-interval procedure A sample mean, sample size, population standard deviation, and confidence level are provided. Use this information to complete parts (a) through (c) below. \\(\\bar{x}=24, n=37, \\sigma=3, confidence level = 95%\\) (a). Use the one-mean z-interval procedure to find a confidence interval for the mean of the population from which the sample was drawn. First, we need to get the data from the question x = 24 n = 37 sigma = 3 alpha = .05 We do not use the empirical rule like in question 8.1.11 To find confidence interval, we use formulas \\(\\bar{x} \\pm z_{\\frac{\\alpha}{2}}.\\frac{\\sigma}{\\sqrt{n}}\\) First we find \\(z_{\\frac{\\alpha}{2}}\\) by using qnorm() zalpha2 = abs(qnorm(alpha/2)) zalpha2 ## [1] 1.959964 To find 95% confidence interval, we run x - zalpha2 * sigma/sqrt(n) ## [1] 23.03335 x + zalpha2 * sigma/sqrt(n) ## [1] 24.96665 Round to one decimal places as needed round(x - zalpha2 * sigma/sqrt(n), 1) ## [1] 23 round(x + zalpha2 * sigma/sqrt(n), 1) ## [1] 25 (b).Obtain the margin of error by taking half the length of the confidence interval.What is the length of the confidence interval? Length of confidence interval round(x + zalpha2 * sigma/sqrt(n), 1)-round(x - zalpha2 * sigma/sqrt(n), 1) ## [1] 2 Margin of error = 1/2 distance of two endpoints of confidence interval (round(x + zalpha2 * sigma/sqrt(n), 1)-round(x - zalpha2 * sigma/sqrt(n), 1)) /2 ## [1] 1 (c). Obtain the margin of error by using the formula \\(E=z_{\\frac{\\alpha}{2}}.\\frac{\\sigma}{\\sqrt{n}}\\) Identify the critical value. zalpha2 ## [1] 1.959964 round(zalpha2,2) ## [1] 1.96 We can find margin of error E = zalpha2 * sigma/sqrt(n) E ## [1] 0.9666483 round(E, 1) ## [1] 1 Hope that helps! "],["one-sample-t-test.html", "8.3.130 one sample t-test", " 8.3.130 one sample t-test The following data represent the concentration of organic carbon (mg/L) collected from organic soil. Construct a 99% confidence interval for the mean concentration of dissolved organic carbon collected from organic soil. (Note: \\(\\bar x\\) = 16.56 mg/L and s = 8.3 mg/L) Construct a 99 % confidence interval for the mean concentration of dissolved organic carbon collected from organic soil. Since the question gives t-distribution table we will use t-test. First, we need to get the data from Excel. (The approach below gets the data mannually) data &lt;- c(14.00, 8.81, 30.91, 19.80, 29.80, 7.40, 14.86, 14.86, 27.10, 20.46, 14.00, 8.09, 16.51, 14.90, 15.35, 5.30, 7.40, 33.67, 9.72, 18.30) To get 99% confidence interval, we run t.test(data, conf.level = .99) ## ## One Sample t-test ## ## data: data ## t = 8.9198, df = 19, p-value = 3.21e-08 ## alternative hypothesis: true mean is not equal to 0 ## 99 percent confidence interval: ## 11.24988 21.87412 ## sample estimates: ## mean of x ## 16.562 To get the data in 2 decimal places, we run print(t.test(data, conf.level = .99), 4) ## ## One Sample t-test ## ## data: data ## t = 8.9, df = 19, p-value = 3e-08 ## alternative hypothesis: true mean is not equal to 0 ## 99 percent confidence interval: ## 11.25 21.87 ## sample estimates: ## mean of x ## 16.56 As you can see 99% confidence interval is from 11.25, 21.87 Hope that helps! "],["left-tailed-z-test-without-data.html", "9.4.77 left-tailed z-test without data", " 9.4.77 left-tailed z-test without data A sample mean, sample size, and population standard deviation are provided below. Use the one-mean z-test to perform the required hypothesis test at the 1% significance level. \\(\\bar x\\) = 17, n =34, \\(\\sigma\\) = 10, \\(H_0: \\mu =22, H_a: \\mu &lt; 22\\) The test statistic is z = First, we need to get the data the question x = 17 n = 34 sigma = 10 mu = 22 To get the test statistic z we use the formular \\(z = (\\bar x-\\mu)/(\\sigma/\\sqrt{n})\\), we run z = (x-mu)/(sigma/sqrt(n)) z ## [1] -2.915476 Round the answer to two decimal places round(z,2) ## [1] -2.92 (b) Identify the critical value(s). Select the correct choice below and fill in the answer box within your choice. (Round to two decimal places as needed.). First, this is a left tail test since \\(H_a: \\mu &lt; 22\\), we have the negative critical value which is on the left of the graph. Since the significance level is 1%, we can use qnorm() to get the z value qnorm(.01) ## [1] -2.326348 Round to two decimal places round(qnorm(.01), 2) ## [1] -2.33 Since our test statistic z = -2.92 &lt; our critical value \\(z_{\\alpha}\\) = -2.33, out test statistic lies in the rejected region. So we have enough evidence to reject null hypothesis. Hope that helps! "],["left-tailed-z-test-with-data.html", "9.4.85 left-tailed z-test with data", " 9.4.85 left-tailed z-test with data The recommended dietary allowance (RDA) of iron for adult females is 18 milligrams (mg) per day. The given iron intakes (mg) were obtained for 45 random adult females. At the 10 % significance level, do the data suggest that adult females are, on average, getting less than the RDA of 18 mg of iron? Assume that the population standard deviation is 4.6mg. Preliminary data analyses indicate that applying the z-test is reasonable. (Note: \\(\\bar x\\) =14.66 ) The test statistic is z = First, we need to import data from Excel. (Here we get the data mannually) data = c(14.9, 17.5, 14.7, 14.7, 10.6, 18.5, 18.1, 18.8, 15.4, 16, 12.6, 16.3, 21.1, 19.1, 11.6, 12.5, 15.1, 11, 15.3, 9.5, 18.8, 17.8, 13.9, 16.3, 11.6, 15.9, 12.6, 14.5, 11.4, 13, 18.5, 13, 11.7, 10.8, 17.7, 12, 17.7, 6.4, 16.9, 12.6, 16.5, 14.7, 13.2, 16.8, 12) The question provides sample mean \\(\\bar x\\) =14.66. Since we have the data, we could check it by running mean() command mean(data) ## [1] 14.65778 round(mean(data), 2) ## [1] 14.66 The given iron intakes (mg) were obtained for 45 random adult females. So the sample size is 45. We can get it by using length() command length(data) ## [1] 45 Assume that the population standard deviation is 4.6 mg. Since the question assumes that we know the population standard deviation and the sample size is greater 30. We can run z-test. If the population standard deviation is unknown and the sample size is small, t-test is prefered. At the 10 % significance level, do the data suggest that adult females are, on average, getting less than the RDA of 18 mg of iron \\(H_0: \\mu = 18 mg\\) \\(H_a: \\mu &lt; 18 mg\\) Now, we need to import the data from the question x = 14.66 mu = 18 n = 45 sigma = 4.6 To get the test statistic z we use the formular \\(z = (\\bar x-\\mu)/(\\sigma/\\sqrt{n})\\), we run z = (x-mu)/(sigma/sqrt(n)) z ## [1] -4.870739 Round the answer to two decimal places round(z,2) ## [1] -4.87 Determine the critical value(s). Select the correct choice below and fill in the answer box within your choice. (Round to two decimal places as needed.). First, this is a left tail test since \\(H_a: \\mu &lt; 18\\), we have the negative critical value which is on the left of the graph. Since the significance level is 10%, we can use qnorm() to get the z value qnorm(.1) ## [1] -1.281552 Round to two decimal places round(qnorm(.1), 2) ## [1] -1.28 Since our test statistic z = -4.87 &lt; our critical value \\(z_{\\alpha}\\) = -1.28, out test statistic lies in the rejected region. So we have enough evidence to reject null hypothesis. Hope that helps! "],["t-test.html", "9.5.111 t-test", " 9.5.111 t-test A sample mean, sample size, and sample standard deviation are provided below. Use the one-mean t-test to perform the required hypothesis test at the 1 % significance level. \\(\\bar x\\) = 21, s = 10, n = 32, $ \\(H_0: \\mu =27, H_a: \\mu \\neq 27\\) The test statistic is t = First, we need to get the data the question x = 21 s = 10 n = 32 mu = 27 To get the test statistic t we use the formular \\(t = \\frac{\\bar x-\\mu}{\\frac{s}{\\sqrt{n}}}\\), we run t = (x-mu)/(s/sqrt(n)) t ## [1] -3.394113 Round the answer to two decimal places round(t,2) ## [1] -3.39 Identify the critical value(s). Select the correct choice below and fill in the answer box within your choice.(Round to three decimal places as needed.). First, this is a two tailed test since \\(H_a: \\mu \\neq 27\\), we have two critical values. We need to find degree of freedom deg = n-1 Since the significance level is 1% and this is a two tail test, the area to the left of a negative critical will be .01/2 We can find the negative critical value by use qt() command qt(.01/2, deg) ## [1] -2.744042 Round to three decimal places round(qt(.01/2, deg),3) ## [1] -2.744 Since our test statistic t = -3.39 &lt; our critical value \\(t_{\\alpha/2}\\) = -2.744, out test statistic lies in the rejected region. So we have enough evidence to reject null hypothesis. Hope that helps! "],["pooled-t-test-two-tailed.html", "10.2.39 pooled t-test two-tailed", " 10.2.39 pooled t-test two-tailed Provided below are summary statistics for independent simple random samples from two populations. Use the pooled t-test and the pooled t-interval procedure to conduct the required hypothesis test and obtain the specified confidence interval. \\(\\bar x_{1} = 15, s_1=2.3, n_1=15\\) \\(\\bar x_{2} = 16, s_2=2.2, n_2=15\\) (a). First, what are the correct hypotheses for a two-tailed test? Since it is a two tailed test, the correct hypothese is \\(H_0: \\mu_1 =\\mu_2\\) \\(H_a: \\mu_1 \\neq \\mu_2\\) Next, compute the test statistic. (Round to three decimal places as needed.) First, we need to get the data from the question x1 = 15 s1 = 2.3 n1 = 15 x2 = 16 s2 = 2.2 n2 = 15 This is a pooled t-test, to compute pooled sample standard deviation we use the formula \\(s_p= \\frac{(n_1-1)s_1^2+(n_2-1)s_2^2}{n_1+n_2-2}\\) sp = sqrt( ( (n1-1)*s1^2 + (n2-1)*s2^2 )/ (n1+n2-2) ) sp ## [1] 2.250555 To get the test statistic t we use the formular \\(t= \\frac{\\bar x_1-\\bar x_2}{s_p \\sqrt{1/n_1+1/n_2}}\\), we run t = (x1-x2)/(sp*sqrt(1/n1+1/n2)) t ## [1] -1.216861 Round the answer to three decimal places round(t,3) ## [1] -1.217 Now determine the critical values. (Round to three decimal places as needed.) We need to find degree of freedom deg = n1+n2-2 Since this is a two-tailed test and \\(\\alpha = .01\\), the area to the left of a negative critical value is equal to \\(\\alpha/2\\) alpha = .01 t_critical = abs(qt(alpha/2,deg)) t_critical ## [1] 2.763262 Round the answer to three decimal places round(t_critical,3) ## [1] 2.763 Since our test statistic t = -1.217 &gt; our negative critical value \\(t_{\\alpha/2}\\) = -2.763 and &lt; our positive critical value \\(t_{\\alpha/2}\\) = 2.763, out test statistic does not lie in the rejected region. So we do not have enough evidence to reject null hypothesis. (b) The 99% confidence interval is from… to… (Round to three decimal places as needed.) 99% confidence interval means \\(\\alpha = .01\\) so \\(t_{\\alpha/2}=t_{critical value}\\) To find confidence interval we use the formular \\((\\bar x_1 - \\bar x_2) \\pm t_{\\alpha/2}.s_p\\sqrt{1/n_1+1/n_2}\\) (x1-x2) - t_critical*sp*sqrt(1/n1+1/n2) ## [1] -3.270812 (x1-x2) + t_critical*sp*sqrt(1/n1+1/n2) ## [1] 1.270812 Round to three decimal places round((x1-x2) - t_critical*sp*sqrt(1/n1+1/n2),3) ## [1] -3.271 round((x1-x2) + t_critical*sp*sqrt(1/n1+1/n2),3) ## [1] 1.271 We finish a lot of complicated work by using R Hope that helps! "],["pooled-t-test-right-tailed.html", "10.2.41 pooled t-test right-tailed", " 10.2.41 pooled t-test right-tailed Provided below are summary statistics for independent simple random samples from two populations. Use the pooled t-test and the pooled t-interval procedure to conduct the required hypothesis test and obtain the specified confidence interval. \\(\\bar x_{1} = 19, s_1=3, n_1=10\\) \\(\\bar x_{2} = 17, s_2=4, n_2=15\\) (a).First, what are the correct hypotheses for a right-tailed test? Since it is a right-tailed test, the correct hypothese is \\(H_0: \\mu_1 =\\mu_2\\) \\(H_a: \\mu_1 &gt; \\mu_2\\) Next, compute the test statistic. (Round to three decimal places as needed.) First, we need to get the data from the question x1 = 19 s1 = 3 n1 = 10 x2 = 17 s2 = 4 n2 = 15 This is a pooled t-test, to compute pooled sample standard deviation we use the formula \\(s_p= \\frac{(n_1-1)s_1^2+(n_2-1)s_2^2}{n_1+n_2-2}\\) sp = sqrt( ( (n1-1)*s1^2 + (n2-1)*s2^2 )/ (n1+n2-2) ) sp ## [1] 3.641548 To get the test statistic t we use the formular \\(t= \\frac{\\bar x_1-\\bar x_2}{s_p \\sqrt{1/n_1+1/n_2}}\\), we run t = (x1-x2)/(sp*sqrt(1/n1+1/n2)) t ## [1] 1.345301 Round the answer to three decimal places round(t,3) ## [1] 1.345 Now determine the critical values. (Round to three decimal places as needed.) We need to find degree of freedom deg = n1+n2-2 Since this is a right-tailed test and \\(\\alpha = .01\\), the area to the left of alpha is equal to \\(1-\\alpha\\) alpha = .05 t_critical = abs(qt(1-alpha,deg)) t_critical ## [1] 1.713872 Round the answer to three decimal places round(t_critical,3) ## [1] 1.714 Since our test statistic t = 1.345 &lt; our critical value \\(t_{\\alpha}\\) = 1.714, out test statistic does not lie in the rejected region. So we do not have enough evidence to reject null hypothesis. (b) The 90% confidence interval is from… to… (Round to three decimal places as needed.) 90% confidence interval means \\(\\alpha = .1\\) so our critical value \\(=\\alpha/2=.05\\) \\(t_{\\alpha/2} = t_{critical value}\\) To find confidence interval we use the formular \\((\\bar x_1 - \\bar x_2) \\pm t_{\\alpha/2}.s_p\\sqrt{1/n_1+1/n_2}\\) (x1-x2) - t_critical*sp*sqrt(1/n1+1/n2) ## [1] -0.5479367 (x1-x2) + t_critical*sp*sqrt(1/n1+1/n2) ## [1] 4.547937 Round to three decimal places round((x1-x2) - t_critical*sp*sqrt(1/n1+1/n2),3) ## [1] -0.548 round((x1-x2) + t_critical*sp*sqrt(1/n1+1/n2),3) ## [1] 4.548 We finish a lot of complicated work by using R Hope that helps! "],["pooled-t-test-with-data.html", "10.2.51 pooled t-test with data", " 10.2.51 pooled t-test with data Preliminary data analyses indicate that you can reasonably consider the assumptions for using pooled t-procedures satisfied. Independent random samples of released prisoners in the fraud and firearms offense categories yielded the following information on time served, in months. Obtain a 95 % confidence interval for the difference between the mean times served by prisoners in the fraud and firearms offense categories. (Note: \\(\\bar x_1=12.12, s_1=3.56, \\bar x_2=15.71, s_2=3.32\\)) The 95% confidence interval is from … to … First, we need to get the data from the question fraud &lt;- c(13.5, 12.6, 16.7, 6.7, 8.4, 16.3, 13.3, 14.3, 12.2, 7.2) firearms &lt;- c(16.4, 10.2, 16.2, 12.4, 17.5, 16.7, 17.6, 17.9, 20.8, 11.4) The note means that these data are optional to know. In the case that the question does not provide these data, we could find sample mean, sample standard deviation, and size by running Round to two decimal places round(mean(fraud), 2) ## [1] 12.12 round(sd(fraud), 2) ## [1] 3.56 length(fraud) ## [1] 10 round(mean(firearms), 2) ## [1] 15.71 round(sd(firearms),2) ## [1] 3.32 length(firearms) ## [1] 10 We have the same data set with the note from the question, we could use the same approach in question 10.2.41 to find confidence interval or we could use t.test() function in R to find confidence interval Since this is a pooled t-test, we specify var.equal = TRUE t.test(fraud, firearms, conf.level=.95, var.equal = TRUE) ## ## Two Sample t-test ## ## data: fraud and firearms ## t = -2.3324, df = 18, p-value = 0.03149 ## alternative hypothesis: true difference in means is not equal to 0 ## 95 percent confidence interval: ## -6.8237597 -0.3562403 ## sample estimates: ## mean of x mean of y ## 12.12 15.71 To have 3 decimal places, we can use print() command print(t.test(fraud, firearms, conf.level=.95, var.equal = TRUE), 3) ## ## Two Sample t-test ## ## data: fraud and firearms ## t = -2, df = 18, p-value = 0.03 ## alternative hypothesis: true difference in means is not equal to 0 ## 95 percent confidence interval: ## -6.824 -0.356 ## sample estimates: ## mean of x mean of y ## 12.1 15.7 To illustate that we will have the same answer when we use the same approach in question 10.2.41 First, we need to get the data from the question x1 = 12.12 s1 = 3.56 n1 = 10 x2 = 15.71 s2 = 3.32 n2 = 10 This is a pooled t-test, to compute pooled sample standard deviation we use the formula \\(s_p= \\frac{(n_1-1)s_1^2+(n_2-1)s_2^2}{n_1+n_2-2}\\) sp = sqrt( ( (n1-1)*s1^2 + (n2-1)*s2^2 )/ (n1+n2-2) ) sp ## [1] 3.442092 We need to find degree of freedom deg = n1+n2-2 Since the confidence level = 0.95, \\(\\alpha = 1-.95=.05\\)To find \\(t_{\\alpha/2}\\) we run alpha = .05 t_alpha2 = abs(qt(alpha/2,deg)) t_alpha2 ## [1] 2.100922 The 95% confidence interval is from… to… (Round to three decimal places as needed.) To find confidence interval we use the formular \\((\\bar x_1 - \\bar x_2) \\pm t_{\\alpha/2}.s_p\\sqrt{1/n_1+1/n_2}\\) (x1-x2) - t_alpha2*sp*sqrt(1/n1+1/n2) ## [1] -6.824055 (x1-x2) + t_alpha2*sp*sqrt(1/n1+1/n2) ## [1] -0.3559446 Round to three decimal places round((x1-x2) - t_alpha2*sp*sqrt(1/n1+1/n2),3) ## [1] -6.824 round((x1-x2) + t_alpha2*sp*sqrt(1/n1+1/n2),3) ## [1] -0.356 We finish a lot of complicated work by using R Hope that helps! "],["nonpooled-t-test-left-tailed.html", "10.3.77 nonpooled t.test left-tailed", " 10.3.77 nonpooled t.test left-tailed Provided below are summary statistics for independent simple random samples from two populations. Use the nonpooled t-test and the nonpooled t-interval procedure to conduct the required hypothesis test and obtain the specified confidence interval. \\(\\bar x_{1} = 18, s_1=3, n_1=20\\) \\(\\bar x_{2} = 21, s_2=5, n_2=15\\) (a). What are the correct hypotheses for a left-tailed test? Since it is a left-tailed test, the correct hypothese is \\(H_0: \\mu_1 =\\mu_2\\) \\(H_a: \\mu_1 &lt; \\mu_2\\) Find the test statistic. (Round to three decimal places as needed.) First, we need to get the data from the question x1 = 18 s1 = 3 n1 = 20 x2 = 21 s2 = 5 n2 = 15 This is a nonpooled t-test, to compute the test statistic t we use the formular \\(t= \\frac{\\bar x_1-\\bar x_2}{\\sqrt{s_1^2/n_1+s_2^2/n_2}}\\) t=(x1-x2)/sqrt((s1^2/n1)+(s2^2)/n2) t ## [1] -2.06203 Round the answer to three decimal places round(t,3) ## [1] -2.062 Now determine the critical values. (Round to three decimal places as needed.) We need to find degree of freedom by using the formula \\(\\Delta=\\frac{[(s_1^2/n_1)+(s_2^2/n_2)]^2}{\\frac{(s_1^2/n_1)^2}{n_1-1}+\\frac{(s_2^2/n_2)^2}{n_2-1}}\\) deg = ((s1^2/n1) + (s2^2/n2))^2 / ( (s1^2/n1)^2/(n1-1) + (s2^2/n2)^2/(n2-1) ) Round down to nearest interger deg = floor(deg) Since this is a left-tailed test and \\(\\alpha = .05\\), the area to the left of \\(\\alpha\\) is equal to \\(\\alpha\\) alpha = .05 t_critical = abs(qt(alpha,deg)) t_critical ## [1] 1.720743 Since we use abs() command so it return the positive value of \\(t_{\\alpha}\\) Round the answer to three decimal places round(t_critical,3) ## [1] 1.721 Since our test statistic t = -2.062 &lt; our critical value \\(t_{\\alpha}\\) = -1.721, out test statistic lies in the rejected region. So we have enough evidence to reject null hypothesis. (b) The 90% confidence interval is from… to… (Round to three decimal places as needed.) 90% confidence interval means \\(\\alpha = .1\\) so our critical value \\(=\\alpha/2=.05\\) \\(t_{\\alpha/2} = t_{critical value}\\) To find confidence interval we use the formular \\((\\bar x_1 - \\bar x_2) \\pm t_{\\alpha/2}.\\sqrt{s_1^2/n_1+s_2^2/n_2}\\) (x1-x2) + t_critical * sqrt(s1^2/n1+s2^2/n2) ## [1] -0.496531 (x1-x2) - t_critical * sqrt(s1^2/n1+s2^2/n2) ## [1] -5.503469 Round to three decimal places round((x1-x2) + t_critical * sqrt(s1^2/n1+s2^2/n2),3) ## [1] -0.497 round((x1-x2) - t_critical * sqrt(s1^2/n1+s2^2/n2),3) ## [1] -5.503 We finish a lot of complicated work by using R Hope that helps! "],["paired-t-test-two-tailed.html", "10.5.149 paired t-test two-tailed", " 10.5.149 paired t-test two-tailed The null hypothesis is \\(H_0:\\mu_1=\\mu_2\\) and the alternative hypothesis is as specified. The provided data are from a simple random paired sample from the two populations under consideration. Use the paired t-test to perform the required hypothesis test at the 10% significance level. \\(H_a:\\mu_1 \\neq \\mu_2\\) Find the test statistic. Use population 1 minus population 2 as the difference. (Round to three decimal places as needed.) First, we need to get the data from the question population1 &lt;- c(5, 19, 20, 21, 7, 10, 9) population2 &lt;- c(3, 18, 17, 15, 3, 11, 6) Use population 1 minus population 2 as the difference. We store difference between population 1 and population 2 in variable difference and run test statistic. Since this is two-tailed test and significant level = 10%, we have confidence level = .9 First approach use t.test() difference = population1 - population2 t.test(difference, conf.level = .9) ## ## One Sample t-test ## ## data: difference ## t = 3.0571, df = 6, p-value = 0.02231 ## alternative hypothesis: true mean is not equal to 0 ## 90 percent confidence interval: ## 0.9369806 4.2058765 ## sample estimates: ## mean of x ## 2.571429 Round to 3 decimal places print(t.test(difference, conf.level = .9),6) ## ## One Sample t-test ## ## data: difference ## t = 3.057, df = 6, p-value = 0.0223 ## alternative hypothesis: true mean is not equal to 0 ## 90 percent confidence interval: ## 0.936981 4.205877 ## sample estimates: ## mean of x ## 2.57143 Since we have 7 pairs of data, our degree of freedom is 7- 1 = 6 and we have two-tailed test with \\(\\alpha = .1\\), the area to the left of negative critical value = \\(\\alpha/2\\) so \\(t_{\\alpha/2}\\) round(qt(.1/2, 6), 3) ## [1] -1.943 Since the test statistic value t = 3.057 is larger than the positive critical value \\(t_{\\alpha/2} = 1.943\\), we have enough evidence to reject hypothesis. Second appraach to find test statistic, we can use formula \\(t=\\frac{\\bar d}{\\frac{s_d}{\\sqrt{n}}}\\) n = 7 mean(difference)/(sd(difference)/sqrt(n)) ## [1] 3.057148 Round to 3 decimal places round(mean(difference)/(sd(difference)/sqrt(n)),3) ## [1] 3.057 It is good to know both approaches so we could check the answer from t.test() in R Hope that helps! "],["paired-t-test-left-tailed.html", "10.5.157 paired t-test left-tailed", " 10.5.157 paired t-test left-tailed A researcher randomly selects 6 fathers who have adult sons and records the fathers’ and sons’ heights to obtain the data shown in the table below. Test the claim that sons are taller than their fathers at the \\(\\alpha =\\) 0.10 level of significance. The normal probability plot and boxplot indicate that the differences are approximately normally distributed with no outliers so the use of a paired t-test is reasonable. What are the hypotheses for the t-test? Note that population 1 is fathers and population 2 is sons. Since test the claim that sons are taller than their fathers, we have left-tailed test \\(H_0:\\mu_1 = \\mu_2\\) \\(H_a:\\mu_1 &lt; \\mu_2\\) First, we need to get the data from the question. (We could import the data from Excel) father &lt;- c(66.6, 74.5, 68.2, 66.6, 73.7, 74.9) son &lt;- c(68.9, 76.0, 67.6, 64.1, 73.0, 79.4) Use population 1 minus population 2 as the difference. We store difference between father and son in variable difference and run test statistic. Since \\(\\alpha = .10\\) we have confidence level = .9 First approach use t.test() difference = father - son t.test(difference, conf.level = .9, alternative = &quot;less&quot;) ## ## One Sample t-test ## ## data: difference ## t = -0.73175, df = 5, p-value = 0.2486 ## alternative hypothesis: true mean is less than 0 ## 90 percent confidence interval: ## -Inf 0.7626912 ## sample estimates: ## mean of x ## -0.75 Round to 3 decimal places print(t.test(difference, conf.level = .9, alternative = &quot;less&quot;),5) ## ## One Sample t-test ## ## data: difference ## t = -0.732, df = 5, p-value = 0.25 ## alternative hypothesis: true mean is less than 0 ## 90 percent confidence interval: ## -Inf 0.76269 ## sample estimates: ## mean of x ## -0.75 Since we have 6 pairs of data, our degree of freedom is 6 - 1 = 5 and we have left-tailed test with \\(\\alpha = .1\\), the area to the left of critical value = \\(\\alpha\\) round(qt(.1, 5), 3) ## [1] -1.476 Since the test statistic value t = -0.732 is larger than the critical value \\(t_{\\alpha} = -1.476\\), we do not have enough evidence to reject hypothesis. Second appraach to find test statistic, we can use formula \\(t=\\frac{\\bar d}{\\frac{s_d}{\\sqrt{n}}}\\) n = 6 mean(difference)/(sd(difference)/sqrt(n)) ## [1] -0.7317508 Round to 3 decimal places round(mean(difference)/(sd(difference)/sqrt(n)),3) ## [1] -0.732 It is good to know both approaches so we could check the answer from t.test() in R Hope that helps! "],["paired-t-test-with-confidence-interval.html", "10.5.161 paired t-test with confidence interval", " 10.5.161 paired t-test with confidence interval A group of 8 students were given the same standardized test twice to see whether retaking the test affected the score. The table gives the score differences for the 8students. Use the paired t-interval procedure to determine a 95% confidence interval for the difference between the mean scores on the first test and the second test (retake). (Note: \\(\\bar d = -1.25, s_d = 50.55\\)) The 95% confidence interval is from … to … First, we need to get the data from the question. (We could import the data from Excel) difference &lt;- c(-30, 30, -40, -40, 80, 60, -50, -20) We can check the data from Note round(mean(difference),2) ## [1] -1.25 round(sd(difference),2) ## [1] 50.55 We have confidence level = .95 First approach use t.test() t.test(difference, conf.level = .95) ## ## One Sample t-test ## ## data: difference ## t = -0.069941, df = 7, p-value = 0.9462 ## alternative hypothesis: true mean is not equal to 0 ## 95 percent confidence interval: ## -43.51131 41.01131 ## sample estimates: ## mean of x ## -1.25 Round to 2 decimal places print(t.test(difference, conf.level = .95),4) ## ## One Sample t-test ## ## data: difference ## t = -0.07, df = 7, p-value = 0.9 ## alternative hypothesis: true mean is not equal to 0 ## 95 percent confidence interval: ## -43.51 41.01 ## sample estimates: ## mean of x ## -1.25 Second appraach to find confidence interval, we can use formula \\(\\bar d \\pm t_{\\alpha/2}.\\frac{s_d}{\\sqrt{n}}\\) Since the confidence level = .95, we have \\(\\alpha = .05\\) alpha = .05 n = length(difference) talpha2 = abs(qt(alpha/2, n-1)) mean(difference) + talpha2 *(sd(difference)/sqrt(n)) ## [1] 41.01131 mean(difference) - talpha2 *(sd(difference)/sqrt(n)) ## [1] -43.51131 Round to 2 decimal places round(mean(difference) + talpha2 *(sd(difference)/sqrt(n)),2) ## [1] 41.01 round(mean(difference) - talpha2 *(sd(difference)/sqrt(n)),2) ## [1] -43.51 It is good to know both approaches so we could check the answer from t.test() in R Hope that helps! "],["random-sample-confidence-interval.html", "12.1.17 random sample confidence interval", " 12.1.17 random sample confidence interval A poll found that 59% of a random sample of 1058 adults said that they believe in ghosts. (a). Determine the margin of error for a 99% confidence interval. (Round to three decimal places as needed.) First, we need to get the data from the question. \\(\\hat{p} = .59\\) n = 1058 p = .56 Since confidence level is .99, \\(\\alpha = 1 - .99 = .01\\). So \\(\\alpha/2=.01/2\\) We can find \\(z_{\\alpha/2}\\) by using qnorm() alpha = .01 zalpha2= abs(qnorm(alpha/2)) We can find the margin of error for a 99% confidence interval by using the formular \\(E=z_{\\alpha/2}.\\sqrt{\\frac{\\hat{p}(1-\\hat{p})}{n}}\\) E = zalpha2 * sqrt(p*(1-p)/n) E ## [1] 0.03930924 Round to three decimal places round(E, 3) ## [1] 0.039 (b). Without doing any calculations, indicate whether the margin of error is larger or smaller for a 90% confidence interval. If we change the confidence level from 99% to 90%, our \\(z_{\\alpha/2}\\) will become smaller since alpha increases. From the formular, we can see that margin of error E will decrease. Hope that helps! "],["one-proportion-z-interval.html", "12.1.25 one-proportion z-interval", " 12.1.25 one-proportion z-interval Given below are the number of successes and sample size for a simple random sample from a population.x = 7 , n = 40 , 90 % level (a). Determine the sample proportion. x = 7 n = 40 p = x/n p ## [1] 0.175 \\(\\hat{p} = .175\\) (b). Decide whether using the one-proportion z-interval procedure is appropriate. There are two conditions for one-proportion z interval: simple random sample x and n-x are 5 are greater The first condition is passed since the question specifies a simple random sample To check the second condition we can run x &gt;= 5 ## [1] TRUE n-x &gt;= 5 ## [1] TRUE (c). If appropriate, use the one-proportion z-interval procedure to find the confidence interval at the specified confidence level. The 90% confidence interval is from … to … Since confidence level is .9, \\(\\alpha = 1 - .9 = .1\\). So \\(\\alpha/2=.1/2\\) We can find \\(z_{\\alpha/2}\\) by using qnorm() alpha = .1 zalpha2= abs(qnorm(alpha/2)) We can find the margin of error for a 90% confidence interval by using the formular \\(E=z_{\\alpha/2}.\\sqrt{\\frac{\\hat{p}(1-\\hat{p})}{n}}\\) E = zalpha2 * sqrt(p*(1-p)/n) E ## [1] 0.09881964 Round to three decimal places round(E, 3) ## [1] 0.099 We can calculate 90% confidence interval by using the formula \\(\\hat{p} \\pm E\\) or we can calculate it directly by using the formula \\(\\hat{p} \\pm z_{\\alpha/2}.\\sqrt{\\frac{\\hat{p}(1-\\hat{p})}{n}}\\) These two formula gives the same answer p + E ## [1] 0.2738196 p - E ## [1] 0.07618036 Round to three decimal places round(p + E, 3) ## [1] 0.274 round(p - E, 3) ## [1] 0.076 Second approach: we use direct formula p + zalpha2 * sqrt(p*(1-p)/n) ## [1] 0.2738196 p - zalpha2 * sqrt(p*(1-p)/n) ## [1] 0.07618036 Round to three decimal places round(p + zalpha2 * sqrt(p*(1-p)/n), 3) ## [1] 0.274 round(p - zalpha2 * sqrt(p*(1-p)/n), 3) ## [1] 0.076 (d). If appropriate, find the margin of error for the estimate of p and express the confidence interval in terms of the sample proportion and the margin of error If we use the first approach, we already calculate the value of margin of error. round(E, 3) ## [1] 0.099 If we use the second approach, we have to find the value of margin of error one more time. The first approach is nicer and cleaner to use Hope that helps! "],["sample-size-without-educated-guess.html", "12.1.31 sample size without educated guess", " 12.1.31 sample size without educated guess For the specified margin of error and confidence level, obtain a sample size that will ensure a margin of error of at most the one specified. margin of error = 0.05 ; confidence level = 95% Since confidence level is .95, \\(\\alpha = 1 - .95 = .05\\). So \\(\\alpha/2=.05/2\\) We can find \\(z_{\\alpha/2}\\) by using qnorm() alpha = .05 zalpha2= abs(qnorm(alpha/2)) E = .05 From question 12.1.25 we can find the margin of error for a 95% confidence interval by using the formular \\(E=z_{\\alpha/2}.\\sqrt{\\frac{\\hat{p}(1-\\hat{p})}{n}}\\) This question is reverse, instead of finding E, the question gives us margin of error E and confidence level, ask us to find sample size n to meet the requirement. As professor Covert introduces in chapter 12 worksheet, we can derive the formula \\(E=z_{\\alpha/2}.\\sqrt{\\frac{\\hat{p}(1-\\hat{p})}{n}}\\) to \\(n=\\hat{p}.(1-\\hat{p}).(\\frac{z_{\\alpha/2}}{E})^2\\) Since the proportion \\(\\hat{p}\\) runs from 0 to 1 so \\(\\hat{p}.(1-\\hat{p})\\) will have the maximum value at \\(\\hat{p}=.5\\) or \\(\\hat{p}.(1-\\hat{p}) =.25\\) For example, if we let \\(\\hat{p} = x\\) and \\(y= \\hat{p}.(1-\\hat{p})\\) we have \\(y = -x^2 + x\\). This parabola has vertex at \\(x=-\\frac{b}{2a}=-\\frac{1}{2.(-1)}=\\frac{1}{2}\\) and \\(y = -(\\frac{1}{2})^2+\\frac{1}{2}=\\frac{1}{4}\\) Since we do not know the sample proportion \\(\\hat{p}\\), we know that \\(n \\le \\frac{1}{4}.(\\frac{z_{\\alpha/2}}{E})^2\\) The question asks obtain a sample size that will ensure a margin of error of at most the one specified. We find the sample size by using the formula \\(n = \\frac{1}{4}.(\\frac{z_{\\alpha/2}}{E})^2\\) n = 0.25 * (zalpha2 / E)^2 n ## [1] 384.1459 Round up to nearest integer ceiling(n) ## [1] 385 Hope that helps! "],["sample-size-with-educated-guess.html", "12.1.37 sample size with educated guess", " 12.1.37 sample size with educated guess For the specified margin of error, confidence level, and educated guess for the observed value, obtain a sample size that will ensure a margin of error of at most the one specified (provided, of course, that that observed value of the sample proportion is further from 0.5 than the educated guess). margin of error = 0.03 ; confidence level = 90%;educated guess = 0.56 Since confidence level is .90, \\(\\alpha = 1 - .9 = .1\\). So \\(\\alpha/2=.1/2\\) We can find \\(z_{\\alpha/2}\\) by using qnorm() alpha = .1 zalpha2= abs(qnorm(alpha/2)) p = .56 E = .03 This question is similar to 12.1.31, in this case we have proportion \\(\\hat{p} = .56\\) From question 12.1.25 we can find the margin of error for a 90% confidence interval by using the formular \\(E=z_{\\alpha/2}.\\sqrt{\\frac{\\hat{p}(1-\\hat{p})}{n}}\\) This question is reverse, instead of finding E, the question gives us margin of error E and confidence level, ask us to find sample size n to meet the requirement. As professor Covert introduces in chapter 12 worksheet, we can derive the formula \\(E=z_{\\alpha/2}.\\sqrt{\\frac{\\hat{p}(1-\\hat{p})}{n}}\\) to \\(n=\\hat{p}.(1-\\hat{p}).(\\frac{z_{\\alpha/2}}{E})^2\\) We find the sample size by using the formula \\(n=\\hat{p}.(1-\\hat{p}).(\\frac{z_{\\alpha/2}}{E})^2\\) n = p*(1-p) * (zalpha2 / E)^2 n ## [1] 740.7177 Round up to nearest integer ceiling(n) ## [1] 741 Hope that helps! "],["one-proportion-z-test.html", "12.2.81 one-proportion z-test", " 12.2.81 one-proportion z-test The number of successes and the sample size for a simple random sample from a population are given below. \\(x = 8, n = 32, H_0: p=0.2, H_a:p \\ne 0.2, \\alpha =.05\\) b. Decide whether using the one-proportion z-test is appropriate. c. If appropriate, use the one-proportion z-test to perform the specified hypothesis test. (a). Determine the sample proportion. We use the formula \\(\\hat{p}= \\frac{x}{n}\\) x = 8 n = 32 p = x/n p ## [1] 0.25 \\(\\hat{p} = .25\\) (b). Decide whether using the one-proportion z-interval procedure is appropriate. There are two conditions for one-proportion z test: simple random sample \\(np_0\\) and \\(n(1-p_0)\\) are 5 are greater The first condition is passed since the question specifies a simple random sample To check the second condition we can run p0 = .2 n*p0 &gt;=5 ## [1] TRUE n*(1-p0) &gt;=5 ## [1] TRUE (c).If appropriate, use the one-proportion z-test to perform the specified hypothesis test. To compute test statistic z we use the formula \\(z=\\frac{\\hat{p}-p_0}{\\sqrt{p_0(1-p_0)/n}}\\) z = (p-p0)/sqrt(p0*(1-p0)/n) z ## [1] 0.7071068 Round to two decimal places round(z,2) ## [1] 0.71 Identify the critical value(s), if appropriate. Select the correct choice below and, if necessary, fill in the answer box to complete your answer. Since we have \\(H_a:p \\ne .2\\), this is a two tailed test with \\(\\alpha = 0.05\\). So \\(\\alpha/2= .05/2\\) To find negative critical value, we run round(qnorm(.05/2),2) ## [1] -1.96 Since \\(-z_{\\alpha/2}=-1.96&lt; z = .71&lt; z_{\\alpha/2}=1.96\\), the test statistic does not lie in rejected region. We do not have enough evidence to reject hypothesis. Hope that helps! "],["two-proportion-z-test.html", "12.3.101 two proportion z-test", " 12.3.101 two proportion z-test The numbers of successes and the sample sizes for independent simple random samples from two populations are provided for a left-tailed test and an 80% confidence interval. Complete parts (a) through (d). \\(x_1 = 20, n_1 = 50,x_2 = 23, n_2 = 50, \\alpha =.10\\) (a). Determine the sample proportion. We use the formula \\(\\hat{p}= \\frac{x}{n}\\) x1 = 20 n1 = 50 p1 = x1/n1 p1 ## [1] 0.4 \\(\\hat{p_1} = .4\\) x2 = 23 n2 = 50 p2 = x2/n2 p2 ## [1] 0.46 round(p2,3) ## [1] 0.46 \\(\\hat{p_2} = .46\\) p = (x1 + x2)/(n1+n2) p ## [1] 0.43 round(p,3) ## [1] 0.43 \\(\\hat{p} = .43\\) (b) Decide whether using the two-proportions z-procedures is appropriate. There are two conditions for two-proportions z test: simple random sample \\(x_1,n_1-x_1,x_2,n_2-x_2,\\) are 5 are greater The first condition is passed since the question specifies a simple random sample To check the second condition we can run x1 &gt;= 5 ## [1] TRUE n1 - x1 &gt;= 5 ## [1] TRUE x2 &gt;= 5 ## [1] TRUE n2 - x2 &gt;= 5 ## [1] TRUE (c).If appropriate, use the two-proportions z-test to conduct the required hypothesis test.What are the hypotheses for this test?. Since this is a left-tailted test, we have \\(H_0:p_1=p_2, H_a:p_1&lt;p_2\\) To compute test statistic z we use the formula \\(z=\\frac{\\hat{p_1}-\\hat{p_2}}{\\sqrt{\\hat{p_p}(1-\\hat{p_p})}.\\sqrt{(\\frac{1}{n_1})+(\\frac{1}{n_2})}}\\) z = (p1 -p2)/(sqrt(p*(1-p)) * sqrt(1/n1+1/n2)) z ## [1] -0.6059679 Round to two decimal places round(z,2) ## [1] -0.61 Identify the critical value(s), if appropriate. Select the correct choice below and, if necessary, fill in the answer box to complete your answer. It is a left-tailed test with \\(\\alpha = .1\\), so the area to the left of critical value = .1 To find negative critical value, we run round(qnorm(.1),2) ## [1] -1.28 Since \\(-z_{\\alpha}=-1.28&lt; z = -.61\\) the test statistic does not lie in rejected region. We do not have enough evidence to reject hypothesis. (d) If appropriate, use the two-proportions z-interval procedure to find the specified confidence interval. Select the correct choice below and, if necessary, fill in the answer boxes to complete your answer. The 80% confidence interval is from… to… First approach we calculate confidence interval using margin of error To calculate margin of error we use formula \\(E=z_{\\alpha/2}.\\sqrt{\\frac{\\hat{p_1}(1-\\hat{p1})}{n_1}+\\frac{\\hat{p_2}(1-\\hat{p2})}{n_2}}\\) Since the confidence level is .8, we have \\(\\alpha = .2\\) and \\(\\alpha/2=.1\\) alpha = .2 zalpha2 = abs(qnorm(alpha/2)) E = zalpha2 * sqrt(p1*(1-p1)/n1 + p2*(1-p2)/n2) E ## [1] 0.1266598 To calculate the confidence interval, we use the formula \\((\\hat{p_1}-\\hat{p_2}) \\pm E\\) (p1-p2) + E ## [1] 0.06665983 (p1-p2) - E ## [1] -0.1866598 Round to three decimal places round((p1-p2) + E, 3) ## [1] 0.067 round((p1-p2) - E, 3) ## [1] -0.187 Second approach: find confidence interval directly without using margin of error E To calculate the confidence interval, we use the formula \\((\\hat{p_1}-\\hat{p_2}) \\pm z_{\\alpha/2}.\\sqrt{\\frac{\\hat{p_1}(1-\\hat{p_1})}{n_1}+\\frac{\\hat{p_2}(1-\\hat{p_2})}{n_2}}\\) alpha = .2 zalpha2 = abs(qnorm(alpha/2)) (p1-p2) + zalpha2 * sqrt(p1*(1-p1)/n1 + p2*(1-p2)/n2) ## [1] 0.06665983 (p1-p2) - zalpha2 * sqrt(p1*(1-p1)/n1 + p2*(1-p2)/n2) ## [1] -0.1866598 Round to three decimal places round((p1-p2) + zalpha2 * sqrt(p1*(1-p1)/n1 + p2*(1-p2)/n2),3) ## [1] 0.067 round((p1-p2) - zalpha2 * sqrt(p1*(1-p1)/n1 + p2*(1-p2)/n2),3) ## [1] -0.187 Notes: confidence interval is a range of data that contain unknown population and critical value is where we split the data to rejected and non-rejected region Hope that helps! "],["chi-squared-value.html", "13.1.5 chi squared -value", " 13.1.5 chi squared -value For a \\(\\chi^2\\)-curve with 22 degrees of freedom, find the chi squared -value that has area 0.05 to its right. \\(\\chi_\\alpha^2\\) has \\(\\alpha\\) is the area to the right under \\(\\chi\\) curve We can get \\(\\chi^2\\) value by using the table or we can run qchisq() qchisq() takes in the area to the left and degree of freedom qchisq(.95,22) ## [1] 33.92444 Round to three decimal places round(qchisq(.95,22),3) ## [1] 33.924 Hope that helps! "],["chi-squaredtest.html", "13.2.18 chi squared test", " 13.2.18 chi squared test A distribution and the observed frequencies of the values of a variable from a simple random sample of the population are provided below. Use the chi-square goodness-of-fit test to decide, at the specified significance level, whether the distribution of the variable differs from the given distribution. Distribution: 0.1875, 0.1875, 0.3125, 0.3125 Observed frequencies: 20, 22, 20, 34 Significance level = 0.05 Determine the null and alternative hypotheses. Choose the correct answer below. Since the question asks whether the distribution of the variable differs from the given distribution, it is a two-tailed test \\(H_0:\\) The distribution of the variable is the same as the given distribution \\(H_a:\\) The distribution of the variable differs from given distribution Compute the value of the test statistic,\\(\\chi^2\\) First we need to get the data from the question. (We can import it from Excel) distribution &lt;- c(0.1875, 0.1875, 0.3125, 0.3125) obFrequency &lt;- c(20, 22, 20, 34) First approach, we can use chisq.test() chisq.test(obFrequency,p=distribution, correct=FALSE) ## ## Chi-squared test for given probabilities ## ## data: obFrequency ## X-squared = 4.9778, df = 3, p-value = 0.1734 Round to 3 decimal places print(chisq.test(obFrequency,p=distribution, correct=FALSE),6) ## ## Chi-squared test for given probabilities ## ## data: obFrequency ## X-squared = 4.978, df = 3, p-value = 0.173 Second approach using formular We can find the test statistic \\(\\chi^2\\) by using the formula \\(\\chi^2=\\sum{\\frac{(O-E)^2}{E}}\\) Expected frequency = sample size * distribution We can find the sample size by using sum(obFrequency) in R expFrequency = sum(obFrequency)*distribution sum((obFrequency-expFrequency)^2/expFrequency) ## [1] 4.977778 Round to three decimal places round(sum((obFrequency-expFrequency)^2/expFrequency),3) ## [1] 4.978 \\(\\chi^2\\) is right-tailed test by nature Since we have \\(\\alpha=.05\\) and there are 4 possible values for the variable, so the degree of freedom df = 4 -1 = 3 \\(\\chi_\\alpha^2\\) has \\(\\alpha\\) is the area to the right under \\(\\chi\\) curve We can get \\(\\chi^2\\) value by using the table or we can run qchisq() qchisq() takes in the area to the left and degree of freedom alpha = .05 df = 4 - 1 qchisq(1-alpha,df) ## [1] 7.814728 Round to three decimal places round(qchisq(1- alpha,df),3) ## [1] 7.815 Since \\(\\chi^2\\) is right-tailed test by nature, our test statistic does not lie in rejected region 4.978 &lt; 7.815 , we do not have enough evidence to reject the hypothesis Hope that helps! "],["contingency-table.html", "13.3.43 contingency table", " 13.3.43 contingency table The table provides data on gender and college for the students in one section of the course Introduction to Computer Science. In the table, we have used the abbreviations BUS for Business, ENG for Engineering and Applied Sciences, and LIB Group the bivariate data into a contingency table. First we need to get the data from the question. (We can import it from Excel) data &lt;- read.csv(&quot;https://raw.githubusercontent.com/sileaderwt/MTH1320-UMSL/main/Image%2BData/13.3.43/13.3.43.csv&quot;) data ## Gender College ## 1 M ENG ## 2 M LIB ## 3 F BUS ## 4 F ENG ## 5 M BUS ## 6 M ENG ## 7 M LIB ## 8 M ENG ## 9 M BUS ## 10 M BUS ## 11 M ENG ## 12 M BUS ## 13 M ENG ## 14 F LIB ## 15 M LIB ## 16 F ENG ## 17 F LIB ## 18 F BUS ## 19 F ENG ## 20 F BUS We store data into 2 variables Gender and College Gender = data$Gender College = data$College First we can find total Male and Female table(Gender) ## Gender ## F M ## 8 12 Then we can find the total of BUS, ENG, and LIB table(College) ## College ## BUS ENG LIB ## 7 8 5 We can finish a contingency table by running table(paste(College,Gender)) ## ## BUS F BUS M ENG F ENG M LIB F LIB M ## 3 4 3 5 2 3 Total sum(as.integer(table(Gender))) ## [1] 20 Hope that helps! "],["expected-frequencies.html", "13.4.75 expected frequencies", " 13.4.75 expected frequencies The contingency table shown to the right gives a cross-classification of a random sample of values for two variables, x and y, of a population. First we need to get the data from the question. (We can import it from Excel) data &lt;- read.csv(&quot;https://raw.githubusercontent.com/sileaderwt/MTH1320-UMSL/main/Image%2BData/13.4.75/13.4.75.csv&quot;) data ## X A B ## 1 a 50 20 ## 2 b 10 40 We store data into dframe dframe = data.frame(data) dframe ## X A B ## 1 a 50 20 ## 2 b 10 40 Conditions to run a chi-square test All expected frequencies are 1 or greater At most 20% of the expected frequencies are less than 5 The sample is a simple random sample The sample is an independent sample (a). Compute the expected frequencies and add them into the table given below. First we need to create a new data frame which does not contain a column of names so our data frame only contains data. We can use subset to drop column of name. dframe2 = subset(dframe, select = -c(X)) dframe2 ## A B ## 1 50 20 ## 2 10 40 To see the difference between dframe and dframe2, we can run dframe ## X A B ## 1 a 50 20 ## 2 b 10 40 To find expected frequencies, we can run chisq.test(dframe2, correct=FALSE)$expected ## A B ## 1 35 35 ## 2 25 25 b. The test statistic is We run chisq.test() chisq.test(dframe2, correct=FALSE) ## ## Pearson&#39;s Chi-squared test ## ## data: dframe2 ## X-squared = 30.857, df = 1, p-value = 2.777e-08 round(chisq.test(dframe2, correct=FALSE)$statistic,2) ## X-squared ## 30.86 (c). What are the null and alternative hypotheses? Since chi-square statistic test the independence of two variables, the correct hypothesis is \\(H_0:\\) The two variables, x and y, are not associated \\(H_a:\\) The two variables, x and y, are associated. Since df = 1, to find critical value for \\(\\alpha = .51\\) alpha = .05 round(qchisq(1- alpha,1),3) ## [1] 3.841 Since \\(\\chi^2\\) is right-tailed test by nature, our test statistic lies in rejected region 30.86 &gt; 3.841 , we have enough evidence to reject the hypothesis Hope that helps! "],["chi-squared-test-with-data.html", "13.5.103 chi squared test with data", " 13.5.103 chi squared test with data Perform a chi-square homogeneity test. An independent simple random sample of residents in three regions gave the data on race shown in the table. At the 1 % significance level, do the data provide sufficient evidence to conclude that a difference exists in race distributions among the three regions? Name of variables row total: rTotal column total: cTotal total numbers of data: total original data: dframe1 expected frequencies data: dframe2 What are the null and alternative hypotheses? Since the question asks “that a difference exists in race distributions among the three regions,” the correct hypothesis is \\(H_0:\\) The racial distribution is the same in each of the three regions. \\(H_a:\\) The racial distribution is not the same in each of the three regions. Find the test statistic.,\\(\\chi^2\\) First we need to get the data from the question. (We can import it from Excel) data &lt;- read.csv(&quot;https://raw.githubusercontent.com/sileaderwt/MTH1320-UMSL/main/Image%2BData/13.5.103/13.5.103.csv&quot;) data ## X. White Black Other ## 1 East 99 10 7 ## 2 Midwest 124 18 10 ## 3 West 120 11 20 We store data into 2 different frame. The first one shows original data. The second shows expected frequency. dframe1 = data.frame(data) dframe2 = data.frame(data) Conditions to run a chi-square test All expected frequencies are 1 or greater At most 20% of the expected frequencies are less than 5 The sample is a simple random sample The sample is an independent sample First approach: using chisq() in R which professor Covert introduces in the video lectures.(Recommended) This approach is cleaner and faster First we need to create a new data frame which does not contain a column of names so our data frame only contains data. We can use subset to drop column of name. dframe3 = subset(dframe1, select = -c(X.)) dframe3 ## White Black Other ## 1 99 10 7 ## 2 124 18 10 ## 3 120 11 20 To see the difference between dframe1 and dframe3, we can run dframe1 ## X. White Black Other ## 1 East 99 10 7 ## 2 Midwest 124 18 10 ## 3 West 120 11 20 We run chisq.test() chisq.test(dframe3, correct=FALSE) ## ## Pearson&#39;s Chi-squared test ## ## data: dframe3 ## X-squared = 7.2825, df = 4, p-value = 0.1217 Since df = 4, to find critical value for \\(\\alpha = .01\\) alpha = .01 round(qchisq(1- alpha,4),3) ## [1] 13.277 Since \\(\\chi^2\\) is right-tailed test by nature, our test statistic does not lie in rejected region 7.282 &lt; 13.277 , we do not have enough evidence to reject the hypothesis If the question ask about expected frequencies, we can find it by running chisq.test(dframe3, correct=FALSE)$expected ## White Black Other ## 1 94.95943 10.79714 10.24344 ## 2 124.42959 14.14797 13.42243 ## 3 123.61098 14.05489 13.33413 Second approach using formular First we need to find row total and column total. cTotal = rep(0, nrow(dframe2)) rTotal = c() for (i in 2:ncol(dframe2)){ cTotal = cTotal + dframe2[,i] rTotal = c(rTotal, sum(dframe2[,i])) } total = sum(cTotal) cTotal ## [1] 116 152 151 rTotal ## [1] 343 39 37 total ## [1] 419 We can find the test statistic \\(\\chi^2\\) by using the formula \\(\\chi^2=\\sum{\\frac{(O-E)^2}{E}}\\) for (i in 2:ncol(dframe2)){ dframe2[,i] &lt;- sum(dframe2[,i])*cTotal/total print(dframe2[,i]) } ## [1] 94.95943 124.42959 123.61098 ## [1] 10.79714 14.14797 14.05489 ## [1] 10.24344 13.42243 13.33413 dframe2 ## X. White Black Other ## 1 East 94.95943 10.79714 10.24344 ## 2 Midwest 124.42959 14.14797 13.42243 ## 3 West 123.61098 14.05489 13.33413 Find the test statistic.,\\(\\chi^2\\) chi = 0 for (i in 2:ncol(dframe2)){ chi = chi + sum((dframe1[,i]-dframe2[,i])^2/dframe2[,i]) } chi ## [1] 7.282498 Round to three decimal places round(chi,3) ## [1] 7.282 Find the critical value.\\(\\chi_{\\alpha}^2\\) We find degree of freedom by using the formula \\(df=(r-1)(c-1)\\) Since dframe2 has 4 variables and the first one is x, so ncol(dframe2) returns 1 more than actual value. We find degree of freedom by running df = (ncol(dframe2)-2) * (nrow(dframe2)-1) df ## [1] 4 Our significant level is 1%, so \\(\\alpha = .01\\) alpha = .01 round(qchisq(1- alpha,df),3) ## [1] 13.277 Since \\(\\chi^2\\) is right-tailed test by nature, our test statistic does not lie in rejected region 7.282 &lt; 13.277 , we do not have enough evidence to reject the hypothesis Hope that helps! "],["linear-regression-line.html", "14.2.63 linear regression line", " 14.2.63 linear regression line An instructor asked a random sample of eight students to record their study times at the beginning of a course. She then made a table for total hours studied (x) over 2 weeks and test score (y) at the end of the 2 weeks. The table is given below. Complete parts (a) through (f). \\(\\sum x = 396, \\sum y = 2362, \\sum xy = 118330, \\sum x^2 = 19870\\) (a). Find the regression equation for the data points. First we need to get the data from the question. (We can import it from Excel) x&lt;- c(12, 15, 11, 19, 8, 17, 16, 23) y&lt;- c(95, 76, 80, 75, 90, 75, 83, 75) From formula sheet \\(S_{xx}=\\sum(x_i-\\bar{x})^2=\\sum x_i^2-(\\sum x_i)^2/n\\) \\(S_{xy}=\\sum(x_i-\\bar{x})(y_i-\\bar{y})=\\sum x_iy_i-(\\sum x_i)(\\sum y_i)/n\\) \\(S_{yy}=\\sum(y_i-\\bar{y})^2=\\sum y_i^2-(\\sum y_i)^2/n\\) Regression equation: \\(\\hat{y} = b_0 +b_1x\\) where \\(b_1=\\frac{S_{xy}}{S_{xx}}\\) and \\(b_0 = \\frac{1}{n}(\\sum y_i-b_1\\sum x_i)=\\bar{y} - b_1\\bar{x}\\) Names of variables \\(S_{xx}: Sxx\\) \\(S_{xy}: Sxy\\) \\(S_{yy}: Syy\\) First approach, we find linear regression line by using the formula 1.1 we find \\(S_{xy}, S_{xx}, S_{yy}\\) without finding \\(\\bar x, \\bar y\\) n = length(x) Find \\(S_{xy}, S_{xx}, S_{yy}\\) Syy = sum(y*y) - sum(y)^2/n Sxx = sum(x*x) - sum(x)^2/n Sxy = sum(x*y) - sum(x) * sum(y) /n Sxx ## [1] 158.875 Sxy ## [1] -183.125 Syy ## [1] 414.875 1.2 finding \\(S_{xy}, S_{xx}, S_{yy}\\) using \\(\\bar x, \\bar y\\) Sxx = sum((x-mean(x))^2) Sxy = sum((x-mean(x))*(y-mean(y))) Syy = sum((y-mean(y))^2) Sxx ## [1] 158.875 Sxy ## [1] -183.125 Syy ## [1] 414.875 To find \\(b_0\\) and \\(b_1\\) in the regression equation: \\(\\hat{y} = b_0 +b_1x\\), we run b1 = Sxy / Sxx b1 ## [1] -1.152636 b0 = mean(y) - b1 * mean(x) b0 ## [1] 98.55862 Round to two decimal places round(b1, 2) ## [1] -1.15 round(b0, 2) ## [1] 98.56 Second approach, we find linear regression line by using lm() in R lm(y~x) ## ## Call: ## lm(formula = y ~ x) ## ## Coefficients: ## (Intercept) x ## 98.559 -1.153 In case that R does not give enough accuracy, we use print() print(lm(y~x), 15) ## ## Call: ## lm(formula = y ~ x) ## ## Coefficients: ## (Intercept) x ## 98.55861526357197 -1.15263571990559 Since we have two approaches here, we could do both to double check our answers before submiting. (b). Graph the regression equation and the data points. We draw a graph by using plot() and abline(). Abline() takes 2 arguments y-intercept (\\(b_0\\)) and slope (\\(b_1\\)) plot(x,y) abline(b0, b1) (c) Describe the apparent relationship between the two variables. Since we have negative slope, when x increasess y tends to decrease which means Test Score tends to decrease as Hours Studied increases (d) Identify the predictor and response variables. The predictor variable is x and the response variable is y. So the predictor variable is Hours Studied and the response variable is Test Score. (e) Identify outliers and potential influential observations. “An outlier is an observation that lies outside the overall pattern of the data. In the context of regression analysis, an outlier is a data point that lies far from the regression line relative to the other data points. An influential observation is a data point whose removal causes the regression equation and line to change considerably.” We can tell from the graph that there is no outlier or potential influential observation. (f). Predict the score for a student that studies for 15hours. Since the regression equaation in part a requires rounding the answer to two decimal places b0 = round(b0, 2) b1 = round(b1, 2) b0 ## [1] 98.56 b1 ## [1] -1.15 To find predicted score for a student that studies for 15 hours, we run b0 + 15 * b1 ## [1] 81.31 Round to the nearest whole number as needed ceiling(b0 + 15 * b1) ## [1] 82 Hope that helps! "],["sst-ssr-and-sse.html", "14.3.100 SST, SSR, and SSE", " 14.3.100 SST, SSR, and SSE Following are chest size and weight data for 8 randomly selected bears. Here, x denotes chest size, in inches, and y denotes weight, in pounds. Use the information to do parts (a) through (d). \\(\\sum x = 396, \\sum y = 2362, \\sum xy = 118330, \\sum x^2 = 19870\\) Compute SST, SSR, and SSE, using the formulas, . First we need to get the data from the question. (We can import it from Excel) x&lt;- c(55, 44, 46, 58, 40, 54, 52, 47) y&lt;- c(325, 253, 263, 340, 251, 315, 310, 305) From formula sheet \\(S_{xx}=\\sum(x_i-\\bar{x})^2=\\sum x_i^2-(\\sum x_i)^2/n\\) \\(S_{xy}=\\sum(x_i-\\bar{x})(y_i-\\bar{y})=\\sum x_iy_i-(\\sum x_i)(\\sum y_i)/n\\) \\(S_{yy}=\\sum(y_i-\\bar{y})^2=\\sum y_i^2-(\\sum y_i)^2/n\\) Total sum of squares: \\(SST =\\sum(y_i-\\bar{y})^2 = S_{yy}\\) Regression sum of squares: \\(SSR=\\sum(\\hat{y_i}-\\bar{y})^2=S_{xy}^2/S_{xx}\\) Error sum of squares: \\(SSE=\\sum (y_i-\\hat{y_i})^2=S_{yy} - S_{xy}^2/S_{xx}\\) Regression identity: \\(SST = SSR + SSE\\) Coefficient of determination: \\(r^2=\\frac{SSR}{SST}\\) Linear correlation coefficient: \\(r=\\frac{\\frac{1}{n-1}\\sum(x_i-\\bar{x})(y_i-\\bar{y})}{s_xs_y}\\) or \\(r=\\frac{S_{xy}}{\\sqrt{S_{xx}S_{yy}}}\\) Names of variables \\(S_{xx}: Sxx\\) \\(S_{xy}: Sxy\\) \\(S_{yy}: Syy\\) First approach, we find SST, SSR, SSE without finding \\(\\bar x, \\bar y\\) n = length(x) We have the same dataset from the question. Find \\(S_{xy}, S_{xx}, S_{yy}\\) Syy = sum(y*y) - sum(y)^2/n Sxx = sum(x*x) - sum(x)^2/n Sxy = sum(x*y) - sum(x) * sum(y) /n Sxx ## [1] 268 Sxy ## [1] 1411 Syy ## [1] 8373.5 Find SST SST = Syy SST ## [1] 8373.5 Round to two decimal places round(SST,2) ## [1] 8373.5 Find SSR SSR = Sxy^2/Sxx SSR ## [1] 7428.81 Round to two decimal places round(SSR,2) ## [1] 7428.81 Find SSE SSE = Syy - Sxy^2/Sxx SSE ## [1] 944.6903 Round to two decimal places round(SSE,2) ## [1] 944.69 Check if SSE + SSR = SST SSE + SSR == SST ## [1] TRUE Second approach finding SST, SSR, SSE using \\(\\bar x, \\bar y\\) Sxx = sum((x-mean(x))^2) Sxy = sum((x-mean(x))*(y-mean(y))) Syy = sum((y-mean(y))^2) Sxx ## [1] 268 Sxy ## [1] 1411 Syy ## [1] 8373.5 (b) Compute the coefficient of determination, \\(r^2\\) First approach: using the formula Linear correlation coefficient r = Sxy/sqrt(Sxx*Syy) r ## [1] 0.9419028 Coefficient of determination \\(r^2\\) r^2 ## [1] 0.887181 Round to four decimal places round(r^2, 4) ## [1] 0.8872 Second approach: using summary() in R Multiple R-squared = coefficient of determination summary(lm(y~x)) ## ## Call: ## lm(formula = y ~ x) ## ## Residuals: ## Min 1Q Median 3Q Max ## -13.8228 -6.2799 0.3955 2.6325 22.9123 ## ## Coefficients: ## Estimate Std. Error t value Pr(&gt;|t|) ## (Intercept) 34.6362 38.1993 0.907 0.399502 ## x 5.2649 0.7665 6.869 0.000469 *** ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 ## ## Residual standard error: 12.55 on 6 degrees of freedom ## Multiple R-squared: 0.8872, Adjusted R-squared: 0.8684 ## F-statistic: 47.18 on 1 and 6 DF, p-value: 0.0004691 Third approach: using cor() in R To find r, we run cor(x,y) ## [1] 0.9419028 To find \\(r^2\\), we run cor(x,y)^2 ## [1] 0.887181 Round to 4 decimal places round(cor(x,y)^2, 4) ## [1] 0.8872 (c) Determine the percentage of variation in the observed values of the response variable explained by the regression, and interpret your answer. Show percentage value of \\(r^2\\) round(cor(x,y)^2, 4) * 100 ## [1] 88.72 (d) State how useful the regression equation appears to be for making predictions. Choose the correct answer below. Since the \\(r^2\\) value is close to 1, it is very useful to use regression equation Hope that helps! "],["sst-ssr-and-sse-1.html", "14.3.97 SST, SSR, and SSE", " 14.3.97 SST, SSR, and SSE Use the table and the given regression equation to answer parts (a)-(e). \\(\\hat{y}=7.7 - 1.5x\\) Compute SST, SSR, and SSE, using the formulas, . First we need to get the data from the question. (We can import it from Excel) x&lt;- c(0, 2, 2, 5, 6) y&lt;- c(8, 10, 0, -4, 2) From formula sheet \\(S_{xx}=\\sum(x_i-\\bar{x})^2=\\sum x_i^2-(\\sum x_i)^2/n\\) \\(S_{xy}=\\sum(x_i-\\bar{x})(y_i-\\bar{y})=\\sum x_iy_i-(\\sum x_i)(\\sum y_i)/n\\) \\(S_{yy}=\\sum(y_i-\\bar{y})^2=\\sum y_i^2-(\\sum y_i)^2/n\\) Total sum of squares: \\(SST =\\sum(y_i-\\bar{y})^2 = S_{yy}\\) Regression sum of squares: \\(SSR=\\sum(\\hat{y_i}-\\bar{y})^2=S_{xy}^2/S_{xx}\\) Error sum of squares: \\(SSE=\\sum (y_i-\\hat{y_i})^2=S_{yy} - S_{xy}^2/S_{xx}\\) Regression identity: \\(SST = SSR + SSE\\) Coefficient of determination: \\(r^2=\\frac{SSR}{SST}\\) Linear correlation coefficient: \\(r=\\frac{\\frac{1}{n-1}\\sum(x_i-\\bar{x})(y_i-\\bar{y})}{s_xs_y}\\) or \\(r=\\frac{S_{xy}}{\\sqrt{S_{xx}S_{yy}}}\\) Names of variables \\(S_{xx}: Sxx\\) \\(S_{xy}: Sxy\\) \\(S_{yy}: Syy\\) Compute the three sums of squares, SST, SSR, and SSE, using the defining formulas. Since the quesiton gives linear regression line, we will find SST, SSR, and SSE by using the first formula. We could find SST, SSR, and SSE by using the same approach in question 14.3.100 without linear regression line. We can consider that approach is for double checking purpose. To compute \\(\\hat{y}\\) yh = 7.7 - 1.5 * x Find SST SST = sum( (y-mean(y))^2 ) SST ## [1] 132.8 Find SSR SSR = sum( (yh-mean(y))^2 ) SSR ## [1] 54 Find SSE SSE = sum( (y-yh)^2 ) SSE ## [1] 78.8 (b). Verify the regression identity, SST = SSR + SSE. Is this statement correct? SSE + SSR == SST ## [1] TRUE (c). Determine the value of \\(r^2\\) , the coefficient of determination. Second approach: using summary() in R We can use the formula \\(r^2=\\frac{SSR}{SST}\\) and round to four decimal places round(SSR/SST, 4) ## [1] 0.4066 (d) Determine the percentage of variation in the observed values of the response variable that is explained by the regression. Show percentage value of \\(r^2\\) round(SSR/SST, 4) * 100 ## [1] 40.66 (e) State how useful the regression equation appears to be for making predictions. Since the \\(r^2\\) value is close to .5, it is moderately useful to use regression equation Hope that helps! "],["f-value.html", "16.1.7 F-value", " 16.1.7 F-value An F-curve has df = (6, 4) Use an F-distribution table to find the F-value that has an area of 0.05 to its right. Since \\(\\alpha = .05\\) the area to the left is .95 To find \\(F_{0.05}\\) we run alpha = 0.05 qf(1-alpha, 6,4) ## [1] 6.163132 Round to two decimal places round(qf(1-alpha, 6,4) ,2) ## [1] 6.16 Hope that helps! "],["anova-table.html", "16.3.43 ANOVA table", " 16.3.43 ANOVA table The data shown to the right are from independent simple random samples from three populations. Use these data to complete parts (a) through (d). Notation in one-way ANOVA: k = number of populations n = total number of observations \\(\\bar x\\) = mean of all n observations \\(n_j\\) = size of sample from Population j \\(\\bar{x_j}\\) = mean of sample from Population j \\(s_j^2\\) = variance of sample from Population j \\(T_j\\) = sum of sample data from Population j Defining formulas from sums of squares in one-way ANOVA: SST = \\(\\sum (x_i - \\bar x)^2\\) SSTR = \\(\\sum n_j(\\bar{x_j} - \\bar{x})^2\\) SSE = \\(\\sum (n_j-1)s_j^2\\) One-way ANOVA identity: SST = SSTR + SSE Computing formulas from sums of squares in one-way ANOVA: SST = \\(\\sum x_i^2 - (\\sum x_i)^2/n\\) SSTR = \\(\\sum (T_j^2/n_j) - (\\sum x_i)^2/n\\) SSE = SST - SSTR The way they define \\(\\sum (T_j^2/n_j)\\) is different from the one for x Mean squares in one-way ANOVA: MSTR = \\(\\frac{SSTR}{k-1}\\) MSE = \\(\\frac{SSE}{n-k}\\) SSE = SST - SSTR Test statistic for one-way ANOVAA (independent samples, normal populations, and equal population standard deviations): F = \\(\\frac{MSTR}{MSE}\\) with df = (k - 1, n - k) Confidence interval for \\(\\mu_i - \\mu_j\\) in the Tukey multiple-comparison method (independent samples, normal populations, and equal population sstandard deviations): \\((\\bar{x_i} - \\bar{x_j}) \\pm \\frac{q_{\\alpha}}{\\sqrt{2}}.s\\sqrt{\\frac{1}{n_i} + \\frac{1}{n_j}}\\) where s = \\(\\sqrt{MSE}\\) and \\(q_{\\alpha}\\) is obtained for a q-curve with parameters k and n - k Test statistic for a Kruskal-Wallis test (independent samples, same-shape populations, all sample sizes 5 or greater): \\(K=\\frac{SSTR}{SST/(n-1)}\\) or \\(K=\\frac{12}{n(n+1)}\\sum_{j=1}^{k} \\frac{R_j^2}{n_j} - 3(n+1)\\) where SSTR and SST are computed for the ranks of the data, and \\(R_j\\) denotes the sum of the ranks for the sample data from Population j. K has approximately a chi-square distribution with df = k -1 First approach: Using formulas from the book (a) Compute SST, SSTR, and SSE using the following computing formulas, where \\(x_i\\) is the ith observation, n is the total number of observations, \\(n_j\\) is the sample size for population j, and \\(T_j\\) is the sum of the sample data from population j. First we need to get the data from the question. (We can import it from Excel) data &lt;- read.csv(&quot;https://raw.githubusercontent.com/sileaderwt/MTH1320-UMSL/main/Image%2BData/16.3.43/16.3.43.csv&quot;) data ## Sample1 Sample2 Sample3 ## 1 6 2 1 ## 2 5 3 4 ## 3 4 1 2 ## 4 NA NA 5 The type of data is tibble in R. To avoid confusion when working with other question, we should create a data frame. dframe = data.frame(data) dframe ## Sample1 Sample2 Sample3 ## 1 6 2 1 ## 2 5 3 4 ## 3 4 1 2 ## 4 NA NA 5 Names of variables \\(\\sum{x}: Sx\\) \\(\\sum x^2: Sxx\\) \\(\\sum (T_j^2/n_j)\\): T n = total number of observations: n To make it easy to find \\(\\sum x\\), we store all data into a variable x x &lt;- c() for(item in dframe){ x &lt;- c(x, item[!is.na(item)]) } x ## [1] 6 5 4 2 3 1 1 4 2 5 n = length(x) n ## [1] 10 Find \\(\\sum x_i\\) sum(x) ## [1] 33 Find \\(\\sum x_i^2\\) sum(x*x) ## [1] 137 Find SST To find SST, we use formula SST = \\(\\sum x_i^2 - (\\sum x_i)^2/n\\) SST = sum(x*x) - (sum(x))^2/n SST ## [1] 28.1 Find \\(\\sum (T_j^2/n_j)\\) T = 0 for(item in dframe){ t = item[!is.na(item)] T = T + sum(t)^2/length(t) } T ## [1] 123 Find SSTR, we use formula SSTR = \\(\\sum (T_j^2/n_j) - (\\sum x_i)^2/n\\) SSTR = T - sum(x)^2/n SSTR ## [1] 14.1 Find SSE, we use formula SSE = SST - SSTR SSE = SST - SSTR SSE ## [1] 14 (b). Compare your results in part (a) for SSTR and SSE with the following results from the defining formulas. We find SSTR, SSE, SST by using defining formula Find SST using the formula SST = \\(\\sum (x_i - \\bar x)^2\\) SST = sum(x*x) - (sum(x))^2/n SST ## [1] 28.1 Find SSTR using the formula SSTR = \\(\\sum n_j(\\bar{x_j} - \\bar{x})^2\\) SSTR = 0 for(item in dframe){ t = item[!is.na(item)] SSTR = SSTR + length(t)*(mean(t) - mean(x))^2 } SSTR ## [1] 14.1 Find SSE using the formula SSE = \\(\\sum (n_j-1)s_j^2\\) SSE = 0 for(item in dframe){ t = item[!is.na(item)] SSE = SSE + (length(t)-1)*sd(t)^2 } SSE ## [1] 14 We have the same answer by using two different formulas. (c) Construct a one-way ANOVA table. Find df treatment k = length(dframe) k-1 ## [1] 2 Find SS treatment SSTR ## [1] 14.1 Find MS treatment MSTR = SSTR/(k-1) MSTR ## [1] 7.05 Find Error df n - k ## [1] 7 Find Error SS SSE ## [1] 14 Find Error MS MSE = SSE / (n - k) MSE ## [1] 2 Find F-statistic treatment MSTR / MSE ## [1] 3.525 Find df total n - 1 ## [1] 9 Find SS total SST ## [1] 28.1 (d) Decide, at the 5 % significance level, whether the data provide sufficient evidence to conclude that the means of the populations from which the samples were drawn are not all the same. First, let \\(\\mu_1, \\mu_2,\\) and \\(\\mu_3\\)be the population means of samples 1, 2, and 3, respectively. What are the correct hypotheses for a one-way ANOVA test? \\(H_0: \\mu_1 = \\mu_2 = \\mu_3\\) \\(H_a:\\) Not all the means are equal. Now determine the critical value \\(F_{\\alpha}\\) Since \\(\\alpha = .05\\) alpha = 0.05 qf(1-alpha, k-1, n-k) ## [1] 4.737414 Round to decimal places round(qf(1-alpha, k-1, n-k), 2) ## [1] 4.74 Since our test statistic = 3.53 &lt; our critical value \\(F_{\\alpha}=4.74\\) and it is a right-tailed test, we do not have enough evidence to reject the hypothesis. Second approach: using anova() in R which Professor Covert introduces in the video lectures (recommended) X &lt;- c() len &lt;- c() for(item in dframe){ X &lt;- c(X, item[!is.na(item)]) len &lt;- c(len, length(item[!is.na(item)])) } X ## [1] 6 5 4 2 3 1 1 4 2 5 len ## [1] 3 3 4 We import name of our data. Y= rep(names(dframe), times = len) Y ## [1] &quot;Sample1&quot; &quot;Sample1&quot; &quot;Sample1&quot; &quot;Sample2&quot; &quot;Sample2&quot; &quot;Sample2&quot; &quot;Sample3&quot; ## [8] &quot;Sample3&quot; &quot;Sample3&quot; &quot;Sample3&quot; dframe2 = data.frame(X,Y) dframe2 ## X Y ## 1 6 Sample1 ## 2 5 Sample1 ## 3 4 Sample1 ## 4 2 Sample2 ## 5 3 Sample2 ## 6 1 Sample2 ## 7 1 Sample3 ## 8 4 Sample3 ## 9 2 Sample3 ## 10 5 Sample3 We run anova() fm1 = aov(X~Y, data=dframe2) fm1 ## Call: ## aov(formula = X ~ Y, data = dframe2) ## ## Terms: ## Y Residuals ## Sum of Squares 14.1 14.0 ## Deg. of Freedom 2 7 ## ## Residual standard error: 1.414214 ## Estimated effects may be unbalanced anova(fm1) ## Analysis of Variance Table ## ## Response: X ## Df Sum Sq Mean Sq F value Pr(&gt;F) ## Y 2 14.1 7.05 3.525 0.08729 . ## Residuals 7 14.0 2.00 ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 We can run str() to see structure of our data. We can extract any data from the frame. str(anova(fm1)) ## Classes &#39;anova&#39; and &#39;data.frame&#39;: 2 obs. of 5 variables: ## $ Df : int 2 7 ## $ Sum Sq : num 14.1 14 ## $ Mean Sq: num 7.05 2 ## $ F value: num 3.52 NA ## $ Pr(&gt;F) : num 0.0873 NA ## - attr(*, &quot;heading&quot;)= chr [1:2] &quot;Analysis of Variance Table\\n&quot; &quot;Response: X&quot; Print F-statistic value to 2 decimal places print((anova(fm1)$`F value`), 3) ## [1] 3.52 NA Find df of treatment and error anova(fm1)$`Df` ## [1] 2 7 Find SS of treatment and error to 2 decimal places print((anova(fm1)$`Sum Sq`), 4) ## [1] 14.1 14.0 Find MS of treatment and error to 2 decimal places print((anova(fm1)$`Mean Sq`), 3) ## [1] 7.05 2.00 Find P-value to 2 decimal places print((anova(fm1)$`Pr(&gt;F)`), 3) ## [1] 0.0873 NA Two approaches give the same answer. The second approach is recommended since professor Covert introduces in the video lecture. Now determine the critical value \\(F_{\\alpha}\\) Since \\(\\alpha = .05\\), df(2,7) qf(1-.05, 2, 7) ## [1] 4.737414 Round to decimal places round(qf(1-.05, 2, 7), 2) ## [1] 4.74 Since our test statistic = 3.52 &lt; our critical value \\(F_{\\alpha}=4.74\\) and it is a right-tailed test, we do not have enough evidence to reject the hypothesis. Hope that helps! "],["one-way-anova-test.html", "16.3.49 one-way ANOVA test", " 16.3.49 one-way ANOVA test To see how much difference time of day made on the speed at which he could download files, a college sophomore placed a file on a remote server, then proceeded to download it at three different time periods of the day. He downloaded the file 18 times in all, 6 times at each time of day, and recorded the time in seconds that the download took. At the 5% significance level, do the data provide sufficient evidence to conclude that a difference exists in mean download speed? Notation in one-way ANOVA: k = number of populations n = total number of observations \\(\\bar x\\) = mean of all n observations \\(n_j\\) = size of sample from Population j \\(\\bar{x_j}\\) = mean of sample from Population j \\(s_j^2\\) = variance of sample from Population j \\(T_j\\) = sum of sample data from Population j Defining formulas from sums of squares in one-way ANOVA: SST = \\(\\sum (x_i - \\bar x)^2\\) SSTR = \\(\\sum n_j(\\bar{x_j} - \\bar{x})^2\\) SSE = \\(\\sum (n_j-1)s_j^2\\) One-way ANOVA identity: SST = SSTR + SSE Computing formulas from sums of squares in one-way ANOVA: SST = \\(\\sum x_i^2 - (\\sum x_i)^2/n\\) SSTR = \\(\\sum (T_j^2/n_j) - (\\sum x_i)^2/n\\) SSE = SST - SSTR The way they define \\(\\sum (T_j^2/n_j)\\) is different from the one for x Mean squares in one-way ANOVA: MSTR = \\(\\frac{SSTR}{k-1}\\) MSE = \\(\\frac{SSE}{n-k}\\) SSE = SST - SSTR Test statistic for one-way ANOVAA (independent samples, normal populations, and equal population standard deviations): F = \\(\\frac{MSTR}{MSE}\\) with df = (k - 1, n - k) Confidence interval for \\(\\mu_i - \\mu_j\\) in the Tukey multiple-comparison method (independent samples, normal populations, and equal population sstandard deviations): \\((\\bar{x_i} - \\bar{x_j}) \\pm \\frac{q_{\\alpha}}{\\sqrt{2}}.s\\sqrt{\\frac{1}{n_i} + \\frac{1}{n_j}}\\) where s = \\(\\sqrt{MSE}\\) and \\(q_{\\alpha}\\) is obtained for a q-curve with parameters k and n - k Test statistic for a Kruskal-Wallis test (independent samples, same-shape populations, all sample sizes 5 or greater): \\(K=\\frac{SSTR}{SST/(n-1)}\\) or \\(K=\\frac{12}{n(n+1)}\\sum_{j=1}^{k} \\frac{R_j^2}{n_j} - 3(n+1)\\) where SSTR and SST are computed for the ranks of the data, and \\(R_j\\) denotes the sum of the ranks for the sample data from Population j. K has approximately a chi-square distribution with df = k -1 First, let \\(\\mu_1, \\mu_2,\\) and \\(\\mu_3\\) be the population means times for 7 a.m., 5 p.m., and 12 a.m., respectively. What are the correct hypotheses for a one-way ANOVA test? Since the question asks “At the 5% significance level, do the data provide sufficient evidence to conclude that a difference exists in mean download speed?.” the correct hypothesis is. \\(H_0: \\mu_1 = \\mu_2 = \\mu_3\\) \\(H_a:\\) Not all the means are equal. Now conduct a one-way ANOVA test on the data. What is the F-statistic? First we need to get the data from the question. (We can import it from Excel) data &lt;- read.csv(&quot;https://raw.githubusercontent.com/sileaderwt/MTH1320-UMSL/main/Image%2BData/16.3.49/16.3.49.csv&quot;) data ## Early Evening Late ## 1 70 206 217 ## 2 140 293 177 ## 3 86 251 176 ## 4 209 308 222 ## 5 109 237 212 ## 6 76 209 164 The type of data is tibble in R. To avoid confusion when working with other question, we should create a data frame. dframe = data.frame(data) dframe ## Early Evening Late ## 1 70 206 217 ## 2 140 293 177 ## 3 86 251 176 ## 4 209 308 222 ## 5 109 237 212 ## 6 76 209 164 First approach: using anova() in R which Professor Covert introduces in the video lectures (recommended) X &lt;- c() len &lt;- c() for(item in dframe){ X &lt;- c(X, item[!is.na(item)]) len &lt;- c(len, length(item[!is.na(item)])) } X ## [1] 70 140 86 209 109 76 206 293 251 308 237 209 217 177 176 222 212 164 len ## [1] 6 6 6 We import name of our data. Y= rep(names(dframe), times = len) Y ## [1] &quot;Early&quot; &quot;Early&quot; &quot;Early&quot; &quot;Early&quot; &quot;Early&quot; &quot;Early&quot; &quot;Evening&quot; ## [8] &quot;Evening&quot; &quot;Evening&quot; &quot;Evening&quot; &quot;Evening&quot; &quot;Evening&quot; &quot;Late&quot; &quot;Late&quot; ## [15] &quot;Late&quot; &quot;Late&quot; &quot;Late&quot; &quot;Late&quot; dframe2 = data.frame(X,Y) dframe2 ## X Y ## 1 70 Early ## 2 140 Early ## 3 86 Early ## 4 209 Early ## 5 109 Early ## 6 76 Early ## 7 206 Evening ## 8 293 Evening ## 9 251 Evening ## 10 308 Evening ## 11 237 Evening ## 12 209 Evening ## 13 217 Late ## 14 177 Late ## 15 176 Late ## 16 222 Late ## 17 212 Late ## 18 164 Late We run anova() fm1 = aov(X~Y, data=dframe2) fm1 ## Call: ## aov(formula = X ~ Y, data = dframe2) ## ## Terms: ## Y Residuals ## Sum of Squares 55776.44 26028.67 ## Deg. of Freedom 2 15 ## ## Residual standard error: 41.65627 ## Estimated effects may be unbalanced anova(fm1) ## Analysis of Variance Table ## ## Response: X ## Df Sum Sq Mean Sq F value Pr(&gt;F) ## Y 2 55776 27888.2 16.072 0.0001862 *** ## Residuals 15 26029 1735.2 ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 We can run str() to see structure of our data. We can extract any data from the frame. str(anova(fm1)) ## Classes &#39;anova&#39; and &#39;data.frame&#39;: 2 obs. of 5 variables: ## $ Df : int 2 15 ## $ Sum Sq : num 55776 26029 ## $ Mean Sq: num 27888 1735 ## $ F value: num 16.1 NA ## $ Pr(&gt;F) : num 0.000186 NA ## - attr(*, &quot;heading&quot;)= chr [1:2] &quot;Analysis of Variance Table\\n&quot; &quot;Response: X&quot; Round to 2 decimal places print((anova(fm1)$`F value`), 4) ## [1] 16.07 NA Now determine the critical value \\(F_{\\alpha}\\) Since \\(\\alpha = .05\\), df(2,15) qf(1-.05, 2, 15) ## [1] 3.68232 Round to decimal places round(qf(1-.05, 2, 15), 2) ## [1] 3.68 Since our test statistic = 16.07 &gt; our critical value \\(F_{\\alpha}=3.68\\) and it is a right-tailed test, we have enough evidence to reject the hypothesis. Second approach: using the formula from the book The same approach with question 16.3.43, we could see that two approaches have the same answer (a) Compute SST, SSTR, and SSE using the following computing formulas, where xi is the ith observation, n is the total number of observations, nj is the sample size for population j, and Tj is the sum of the sample data from population j. Names of variables \\(\\sum{x}: Sx\\) \\(\\sum x^2: Sxx\\) \\(\\sum (T_j^2/n_j)\\): T n = total number of observations: n To make it easy to find \\(\\sum x\\), we store all data into a variable x x &lt;- c() for(item in dframe){ x &lt;- c(x, item[!is.na(item)]) } x ## [1] 70 140 86 209 109 76 206 293 251 308 237 209 217 177 176 222 212 164 n = length(x) n ## [1] 18 Find \\(\\sum x_i\\) sum(x) ## [1] 3362 Find \\(\\sum x_i^2\\) sum(x*x) ## [1] 709752 Find SST To find SST, we use formula SST = \\(\\sum x_i^2 - (\\sum x_i)^2/n\\) SST = sum(x*x) - (sum(x))^2/n SST ## [1] 81805.11 Find \\(\\sum (T_j^2/n_j)\\) T = 0 for(item in dframe){ t = item[!is.na(item)] T = T + sum(t)^2/length(t) } T ## [1] 683723.3 Find SSTR, we use formula SSTR = \\(\\sum (T_j^2/n_j) - (\\sum x_i)^2/n\\) SSTR = T - sum(x)^2/n SSTR ## [1] 55776.44 Find SSE, we use formula SSE = SST - SSTR SSE = SST - SSTR SSE ## [1] 26028.67 (b). Compare your results in part (a) for SSTR and SSE with the following results from the defining formulas. We find SSTR, SSE, SST by using defining formula Find SST using the formula SST = \\(\\sum (x_i - \\bar x)^2\\) SST = sum(x*x) - (sum(x))^2/n SST ## [1] 81805.11 Find SSTR using the formula SSTR = \\(\\sum n_j(\\bar{x_j} - \\bar{x})^2\\) SSTR = 0 for(item in dframe){ t = item[!is.na(item)] SSTR = SSTR + length(t)*(mean(t) - mean(x))^2 } SSTR ## [1] 55776.44 Find SSE using the formula SSE = \\(\\sum (n_j-1)s_j^2\\) SSE = 0 for(item in dframe){ t = item[!is.na(item)] SSE = SSE + (length(t)-1)*sd(t)^2 } SSE ## [1] 26028.67 We have the same answer by using two different formulas. (c) Construct a one-way ANOVA table. Find df treatment k = length(dframe) k-1 ## [1] 2 Find SS treatment SSTR ## [1] 55776.44 Find MS treatment MSTR = SSTR/(k-1) MSTR ## [1] 27888.22 Find Error df n - k ## [1] 15 Find Error SS SSE ## [1] 26028.67 Find Error MS MSE = SSE / (n - k) MSE ## [1] 1735.244 Find F-statistic treatment MSTR / MSE ## [1] 16.07164 Find df total n - 1 ## [1] 17 Find SS total SST ## [1] 81805.11 Now determine the critical value \\(F_{\\alpha}\\) Since \\(\\alpha = .05\\) alpha = 0.05 qf(1-alpha, k-1, n-k) ## [1] 3.68232 Round to decimal places round(qf(1-alpha, k-1, n-k), 2) ## [1] 3.68 Hope that helps! "],["one-way-anova-test-1.html", "16.3.60 one-way ANOVA test", " 16.3.60 one-way ANOVA test Researchers analyzed IQ data on preterm children at age 7-8 years. The mothers of the children in the study had chosen whether to provide their infants with breast milk within 72 hours of delivery. The researchers used the following designations. Group I: mothers declined to provide breast milk; Group IIa: mothers had chosen but were unable to provide breast milk; and Group IIb: mothers had chosen and were able to provide breast milk. The summary statistics on IQ are at the right. At the 1 % significance level, do the data provide sufficient evidence to conclude that a difference exists in mean IQ at age 7-8 years for preterm children among the three groups? Critical values are given at the right. Notation in one-way ANOVA: k = number of populations n = total number of observations \\(\\bar x\\) = mean of all n observations \\(n_j\\) = size of sample from Population j \\(\\bar{x_j}\\) = mean of sample from Population j \\(s_j^2\\) = variance of sample from Population j \\(T_j\\) = sum of sample data from Population j Defining formulas from sums of squares in one-way ANOVA: SST = \\(\\sum (x_i - \\bar x)^2\\) SSTR = \\(\\sum n_j(\\bar{x_j} - \\bar{x})^2\\) SSE = \\(\\sum (n_j-1)s_j^2\\) One-way ANOVA identity: SST = SSTR + SSE Computing formulas from sums of squares in one-way ANOVA: SST = \\(\\sum x_i^2 - (\\sum x_i)^2/n\\) SSTR = \\(\\sum (T_j^2/n_j) - (\\sum x_i)^2/n\\) SSE = SST - SSTR The way they define \\(\\sum (T_j^2/n_j)\\) is different from the one for x Mean squares in one-way ANOVA: MSTR = \\(\\frac{SSTR}{k-1}\\) MSE = \\(\\frac{SSE}{n-k}\\) SSE = SST - SSTR Test statistic for one-way ANOVAA (independent samples, normal populations, and equal population standard deviations): F = \\(\\frac{MSTR}{MSE}\\) with df = (k - 1, n - k) Confidence interval for \\(\\mu_i - \\mu_j\\) in the Tukey multiple-comparison method (independent samples, normal populations, and equal population sstandard deviations): \\((\\bar{x_i} - \\bar{x_j}) \\pm \\frac{q_{\\alpha}}{\\sqrt{2}}.s\\sqrt{\\frac{1}{n_i} + \\frac{1}{n_j}}\\) where s = \\(\\sqrt{MSE}\\) and \\(q_{\\alpha}\\) is obtained for a q-curve with parameters k and n - k Test statistic for a Kruskal-Wallis test (independent samples, same-shape populations, all sample sizes 5 or greater): \\(K=\\frac{SSTR}{SST/(n-1)}\\) or \\(K=\\frac{12}{n(n+1)}\\sum_{j=1}^{k} \\frac{R_j^2}{n_j} - 3(n+1)\\) where SSTR and SST are computed for the ranks of the data, and \\(R_j\\) denotes the sum of the ranks for the sample data from Population j. K has approximately a chi-square distribution with df = k -1 (a) Find the null and alternative hypotheses. Choose the correct answer below. Since the question asks that “a difference exists in mean IQ at age 7-8 years for preterm children among the three groups,” the correct hypothesis is. \\(H_0: \\mu_I = \\mu_{IIa} = \\mu_{IIb}\\) \\(H_a:\\) Not all the means are equal. First we need to get the data from the question. nj &lt;- c(88, 17, 195) x &lt;- c(98.6, 97.3, 101.3) s &lt;- c(11.5, 20.6, 13.1) Names of variables n = total number of observations: n We find SSTR, SSE, SST by using defining formula n = sum(nj) k = length(x) Find SSTR using the formula SSTR = \\(\\sum n_j(\\bar{x_j} - \\bar{x})^2\\) SSTR = sum(nj*(x- sum(nj*x)/sum(nj))^2) SSTR ## [1] 602.2155 round(SSTR, 2) ## [1] 602.22 Find SSE using the formula SSE = \\(\\sum (n_j-1)s_j^2\\) SSE = sum((nj-1)*s^2) SSE ## [1] 51587.85 round(SSE, 2) ## [1] 51587.85 Find SST, we use formula SST = SSE + SSTR SST = SSE + SSTR SST ## [1] 52190.07 round(SST, 2) ## [1] 52190.07 Find df treatment k = length(x) k-1 ## [1] 2 Find SS treatment SSTR ## [1] 602.2155 Find MS treatment MSTR = SSTR/(k-1) MSTR ## [1] 301.1077 Find Error df n - k ## [1] 297 Find Error SS SSE ## [1] 51587.85 Find Error MS MSE = SSE / (n - k) MSE ## [1] 173.6965 Find F-statistic treatment MSTR / MSE ## [1] 1.733528 round(MSTR / MSE, 2) ## [1] 1.73 Find df total n - 1 ## [1] 299 Find SS total SST ## [1] 52190.07 Find the critical value. Since \\(\\alpha = .01\\) alpha = 0.01 qf(1-alpha, k-1, n-k) ## [1] 4.67732 Round to decimal places round(qf(1-alpha, k-1, n-k), 2) ## [1] 4.68 Since our test statistic = 1.73 &lt; our critical value \\(F_{\\alpha}\\)=4.68 and it is a right-tailed test, we do not have enough evidence to reject the hypothesis. Hope that helps! "]]
